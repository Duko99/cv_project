{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce41f25-1c50-4c29-b101-511a646f0d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import os\n",
    "from numba import cuda  # https://stackoverflow.com/a/52354865/6476994\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from readInImages import readInImages\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4128143f-be96-4873-8c1d-159a3edea98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# allows all images to be displayed at once (else only displays the last call to plt.imshow())\n",
    "# https://stackoverflow.com/a/41210974\n",
    "def displayImage(image, caption = None, colour = None) -> None:\n",
    "    plt.figure(figsize=(10,10))\n",
    "    if(colour != None):\n",
    "        plt.imshow(image, cmap=colour)\n",
    "    else:\n",
    "        plt.imshow(image)\n",
    "        \n",
    "    if(caption != None):\n",
    "        # display caption below picture (https://stackoverflow.com/a/51486361)\n",
    "        plt.figtext(0.5, 0.01, caption, wrap=True, horizontalalignment='center', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe8bd78-45aa-4da8-8fd6-51afb54f4a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_load = 'final/ZFNet-map-baseline-1'\n",
    "# model_to_load = 'final/ZFNet-map-pre-processing-hist-eq-dark-and-canny-non-empty-1'\n",
    "\n",
    "# model_to_load = 'final/InceptionV3-map-baseline-1'\n",
    "# model_to_load = 'final/InceptionV3-map-pre-processing-hist-eq-dark-and-canny-non-empty-1'\n",
    "\n",
    "# model_to_load = 'final/custom-architecture-map-baseline-1'\n",
    "# model_to_load = 'final/custom-architecture-map-pre-processing-hist-eq-dark-and-canny-non-empty-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b17262-15a8-4cd9-842d-b7d40e9a5685",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('saved_models/{}.h5'.format(model_to_load))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707e6150-e93b-459b-900a-37af8f555877",
   "metadata": {},
   "source": [
    "## Use a distinct dataset to assess trained model's performance\n",
    "* still camera trap images from same location(s), but subset was not used for training, validation, or testing\n",
    "* note: images are not pre-processed, and are simply loaded in and resized\n",
    "* TODO: use Australian camera trap images from different location(s) to assess performance\n",
    "* TODO: save image/prediction pairs - will allow inputting many images to classify without having to display them all, which uses a lot of memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a0f5e5-6292-47b2-89c3-630bc2204629",
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabelled_test_images = []\n",
    "folders_dataset = next(os.walk('data/unlabelled_test_data'))[1]\n",
    "folders_dataset = sorted(folders_dataset)\n",
    "print('folders_dataset: {}'.format(folders_dataset))\n",
    "all_image_names = []\n",
    "\n",
    "for folder in folders_dataset:\n",
    "    unlabelled_test_images = [*unlabelled_test_images, *readInImages('unlabelled_test_data', folder, False)]\n",
    "    \n",
    "    curr_folder_image_names = next(os.walk('data/unlabelled_test_data/{}'.format(folder)),\n",
    "                         (None, None, []))[2]  # [] if no file    \n",
    "    curr_folder_image_names = sorted(curr_folder_image_names)\n",
    "    curr_folder_and_image_names = []\n",
    "    for curr_folder_image_name in curr_folder_image_names:\n",
    "        curr_folder_and_image_names.append(\"{}/{}\".format(folder, curr_folder_image_name))\n",
    "    all_image_names = [*all_image_names, *curr_folder_and_image_names]\n",
    "\n",
    "unlabelled_test_images = np.stack(unlabelled_test_images, axis = 0)\n",
    "print('stacked unlabelled_test_images shape: {}'.format(unlabelled_test_images.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51680332-d010-4dca-8037-cf14fbf3d026",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf4cfc3-f05f-4809-8972-bdb72c8bf4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mappings = ['Bird', 'Cat', 'Dog', 'Empty photo', 'Emu', 'Fox', 'Humman Presense/Deployment', 'Kangaroo', 'Other', 'Rabbit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3625d5b6-6459-48ba-af8a-72a5ac9ac7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_prob = model.predict(unlabelled_test_images)\n",
    "\n",
    "for i in range(len(unlabelled_test_images)):    \n",
    "    sorted_prob = np.sort(predictions_prob[i])\n",
    "    max_pred = sorted_prob[len(sorted_prob) - 1]\n",
    "    # find the index in the unsorted array, as that maps to an index in `class_mappings`\n",
    "    max_pred_index = np.where(predictions_prob[i] == max_pred)[0][0]\n",
    "    \n",
    "    second_max_pred = sorted_prob[len(sorted_prob) - 2]\n",
    "    second_max_pred_index = np.where(predictions_prob[i] == second_max_pred)[0][0]\n",
    "    \n",
    "    third_max_pred = sorted_prob[len(sorted_prob) - 3]\n",
    "    third_max_pred_index = np.where(predictions_prob[i] == third_max_pred)[0][0]\n",
    "    \n",
    "    pred_str = \"Guesses ordered by most probable for image '{}': \".format(all_image_names[i])\n",
    "    pred_str += \"\\n(1) '{}' at {}% \".format(class_mappings[max_pred_index], np.around(float(max_pred * 100), 1))\n",
    "    pred_str += \"\\n(2) '{}' at {}% \".format(class_mappings[second_max_pred_index], np.around(float(second_max_pred * 100), 1))\n",
    "    pred_str += \"\\n(3) '{}' at {}% \".format(class_mappings[third_max_pred_index], np.around(float(third_max_pred * 100), 1))\n",
    "    \n",
    "    displayImage(cv2.cvtColor(unlabelled_test_images[i], cv2.COLOR_BGR2RGB), pred_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56403d34-0c2e-4264-a5d3-ed4eb767209a",
   "metadata": {},
   "source": [
    "## Free up the GPU's memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825257f1-d997-4955-abdc-6fe8e0b64a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda.select_device(0)\n",
    "cuda.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9985fb-824e-48c5-afd0-e895d79f798d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
