{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ad62cb3-b86d-4a0a-8492-ef09608a4c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fix last dense layer. Is it the number of classes? If so then nothing to fix\n",
    "# TODO: discuss how reading in dataset could be made multi-threaded (each dataset is read in on own thread then all joined together at the end)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import imageio as iio\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from numba import cuda  # https://stackoverflow.com/a/52354865/6476994\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "import re\n",
    "from datetime import datetime\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c4a177c-422b-48b4-b51f-ac05542a4e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# allows all images to be displayed at once (else only displays the last call to plt.imshow())\n",
    "# https://stackoverflow.com/a/41210974\n",
    "def displayImage(image, caption = None, colour = None) -> None:\n",
    "    plt.figure()\n",
    "    if(colour != None):\n",
    "        plt.imshow(image, cmap=colour)\n",
    "    else:\n",
    "        plt.imshow(image)\n",
    "        \n",
    "    if(caption != None):\n",
    "        # display caption below picture (https://stackoverflow.com/a/51486361)\n",
    "        plt.figtext(0.5, 0.01, caption, wrap=True, horizontalalignment='center', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7119a4c7-53e6-47b3-a57c-c8c54758002a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_names: ['BB01', 'BB02', 'BB03', 'BB04', 'BB05', 'BB06', 'BB07', 'BB08', 'BB09', 'BB10', 'BB11', 'BB12', 'BB13', 'BB14', 'BB15', 'BB16', 'BB17', 'BB18', 'BB19', 'BB20', 'BB21', 'BB22', 'BB23', 'BB24', 'BB25', 'BB26', 'BB27', 'BB28', 'BB29', 'BB30', 'BB31', 'BB32', 'BB33', 'BB34', 'BB35', 'BB36']\n"
     ]
    }
   ],
   "source": [
    "# dataset_names = [\"BB01\", \"BB02\", \"BB03\", \"BB04\", \"BB05\"]\n",
    "dataset_names = [\"BB01\", \"BB02\", \"BB03\", \"BB04\", \"BB05\", \"BB06\", \"BB07\", \"BB08\", \"BB09\", \"BB10\"]\n",
    "for i in range(11, 37):\n",
    "    dataset_names.append(\"BB{}\".format(i))\n",
    "print(\"dataset_names: {}\".format(dataset_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2162b806-d6bd-47ba-acc3-3f7209a27997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# free up GPU if it didn't after the last run\n",
    "cuda.select_device(0)\n",
    "cuda.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760dbfe7-ea61-44ed-bbbd-1d3d3b576c3f",
   "metadata": {},
   "source": [
    "# Read in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfbb46df-237c-4f68-b1af-5ee75f6b69b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading in images for dataset: BB01\n",
      "all_image_filenames length: 285\n",
      "done current dataset\n",
      "reading in images for dataset: BB02\n",
      "all_image_filenames length: 45\n",
      "done current dataset\n",
      "reading in images for dataset: BB03\n",
      "all_image_filenames length: 230\n",
      "done current dataset\n",
      "reading in images for dataset: BB04\n",
      "all_image_filenames length: 999\n",
      "done current dataset\n",
      "reading in images for dataset: BB05\n",
      "all_image_filenames length: 189\n",
      "done current dataset\n",
      "reading in images for dataset: BB06\n",
      "all_image_filenames length: 1137\n",
      "done current dataset\n",
      "reading in images for dataset: BB07\n",
      "all_image_filenames length: 324\n",
      "done current dataset\n",
      "reading in images for dataset: BB08\n",
      "all_image_filenames length: 66\n",
      "done current dataset\n",
      "reading in images for dataset: BB09\n",
      "all_image_filenames length: 357\n",
      "done current dataset\n",
      "reading in images for dataset: BB10\n",
      "all_image_filenames length: 121\n",
      "done current dataset\n",
      "reading in images for dataset: BB11\n",
      "all_image_filenames length: 167\n",
      "done current dataset\n",
      "reading in images for dataset: BB12\n",
      "all_image_filenames length: 157\n",
      "done current dataset\n",
      "reading in images for dataset: BB13\n",
      "all_image_filenames length: 50\n",
      "done current dataset\n",
      "reading in images for dataset: BB14\n",
      "all_image_filenames length: 367\n",
      "done current dataset\n",
      "reading in images for dataset: BB15\n",
      "all_image_filenames length: 91\n",
      "done current dataset\n",
      "reading in images for dataset: BB16\n",
      "all_image_filenames length: 213\n",
      "done current dataset\n",
      "reading in images for dataset: BB17\n",
      "all_image_filenames length: 26\n",
      "done current dataset\n",
      "reading in images for dataset: BB18\n",
      "all_image_filenames length: 75\n",
      "done current dataset\n",
      "reading in images for dataset: BB19\n",
      "all_image_filenames length: 72\n",
      "done current dataset\n",
      "reading in images for dataset: BB20\n",
      "all_image_filenames length: 96\n",
      "done current dataset\n",
      "reading in images for dataset: BB21\n",
      "all_image_filenames length: 78\n",
      "done current dataset\n",
      "reading in images for dataset: BB22\n",
      "all_image_filenames length: 123\n",
      "done current dataset\n",
      "reading in images for dataset: BB23\n",
      "all_image_filenames length: 192\n",
      "done current dataset\n",
      "reading in images for dataset: BB24\n",
      "all_image_filenames length: 62\n",
      "done current dataset\n",
      "reading in images for dataset: BB25\n",
      "all_image_filenames length: 10\n",
      "done current dataset\n",
      "reading in images for dataset: BB26\n",
      "all_image_filenames length: 142\n",
      "done current dataset\n",
      "reading in images for dataset: BB27\n",
      "all_image_filenames length: 46\n",
      "done current dataset\n",
      "reading in images for dataset: BB28\n",
      "all_image_filenames length: 73\n",
      "done current dataset\n",
      "reading in images for dataset: BB29\n",
      "all_image_filenames length: 20\n",
      "done current dataset\n",
      "reading in images for dataset: BB30\n",
      "all_image_filenames length: 450\n",
      "done current dataset\n",
      "reading in images for dataset: BB31\n",
      "all_image_filenames length: 42\n",
      "done current dataset\n",
      "reading in images for dataset: BB32\n",
      "all_image_filenames length: 268\n",
      "done current dataset\n",
      "reading in images for dataset: BB33\n",
      "all_image_filenames length: 136\n",
      "done current dataset\n",
      "reading in images for dataset: BB34\n",
      "all_image_filenames length: 127\n",
      "done current dataset\n",
      "reading in images for dataset: BB35\n",
      "all_image_filenames length: 45\n",
      "done current dataset\n",
      "reading in images for dataset: BB36\n",
      "all_image_filenames length: 108\n",
      "done current dataset\n"
     ]
    }
   ],
   "source": [
    "# get the all original output filenames\n",
    "def readInImages(datasetName):\n",
    "    print(\"reading in images for dataset: {}\".format(datasetName))\n",
    "    desired_size = 224\n",
    "    image_list = []\n",
    "    imgRegExp = re.compile(r'.*[.](JPG)$')\n",
    "    # https://stackoverflow.com/a/3207973\n",
    "    all_image_filenames = next(os.walk('data/{}'.format(datasetName)),\n",
    "                         (None, None, []))[2]  # [] if no file\n",
    "    # filter out file names that are not JPEGs\n",
    "    all_image_filenames = [i for i in all_image_filenames if imgRegExp.match(i)]\n",
    "    # walk() outputs unordered, so we need to sort\n",
    "    all_image_filenames.sort()\n",
    "    # print(\"all_image_filenames: {}\".format(all_image_filenames))\n",
    "    print(\"all_image_filenames length: {}\".format(len(all_image_filenames)))\n",
    "    for fn in all_image_filenames:\n",
    "        # im = Image.open('data/{}/{}'.format(datasetName, fn))\n",
    "        im = cv2.imread('data/{}/{}'.format(datasetName, fn))\n",
    "        # resize the image to conserve memory, and transform it to be square while\n",
    "        # maintaining the aspect ration (give it padding):\n",
    "        # https://jdhao.github.io/2017/11/06/resize-image-to-square-with-padding/#using-opencv\n",
    "        old_size = im.shape[:2]\n",
    "        ratio = float(desired_size)/max(old_size)\n",
    "        new_size = tuple([int(x*ratio) for x in old_size])\n",
    "        im = cv2.resize(im, (new_size[1], new_size[0]))\n",
    "\n",
    "        delta_w = desired_size - new_size[1]\n",
    "        delta_h = desired_size - new_size[0]\n",
    "        top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "        left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "\n",
    "        color = [0, 0, 0]\n",
    "        new_im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)\n",
    "\n",
    "        \n",
    "        image_list.append(np.asarray(new_im))\n",
    "    \n",
    "    print(\"done current dataset\")\n",
    "    return image_list\n",
    "\n",
    "all_images = []\n",
    "for fn in dataset_names:    \n",
    "    all_images = [*all_images, *readInImages(fn)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aded9195-def1-48e6-bb54-4062ec01dc5b",
   "metadata": {},
   "source": [
    "# Read in dataset's labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d14a993b-efcc-4927-b522-44cbb90e8295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all classes (length=8): {'Other', 'Kangaroo', 'Human Presense/Deployment', 'Cat', 'Empty photo', 'Rabbit', 'Emu', 'Fox'}\n"
     ]
    }
   ],
   "source": [
    "# labels (using dataset's CSV file)\n",
    "\n",
    "def readInAnnotations(datasetName):\n",
    "    labelList = []\n",
    "    # https://realpython.com/python-csv/#reading-csv-files-with-csv\n",
    "    with open('data/{}/{}.csv'.format(datasetName, datasetName)) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        line_count = 0\n",
    "        for row in csv_reader:\n",
    "            # print(\"row: {}\".format(row))\n",
    "            # first row always contains this string, so ignore it\n",
    "            if \"RECONYX - MapView Professional\" in row:\n",
    "                continue\n",
    "            if line_count == 0:\n",
    "                # print(f'Column names are {\", \".join(row)}')\n",
    "                line_count += 1\n",
    "            else:\n",
    "                # print(\"Image Name: {}. Hit List: {}\".format(row[0], row[22].replace(\"\\n\", \", \")))\n",
    "                # FIXME handle when hitlist contains more than one item (e.g., BB06 IMG_512 has 'kangaroo' and 'empty photo') - sort of handled, need to make more dynamic\n",
    "                hit_list = row[22]\n",
    "                if hit_list == '':\n",
    "                    labelList.append(\"Empty photo\")\n",
    "                elif hit_list == 'Empty photo\\nHuman Presense/Deployment':\n",
    "                    labelList.append(\"Human Presense/Deployment\")\n",
    "                elif hit_list == 'Kangaroo\\nEmpty photo':\n",
    "                    labelList.append(\"Kangaroo\")\n",
    "                else:\n",
    "                    # FIXME: rendundant case?\n",
    "                    labelList.append(hit_list.replace(\"\\n\", \", \"))\n",
    "                line_count += 1\n",
    "    # print(\"returning labelList (length: {}): {}\".format(len(labelList), labelList))\n",
    "    # print(\"returning labelList of length: {}\".format(len(labelList)))\n",
    "    return labelList\n",
    "\n",
    "all_image_labels = []\n",
    "for fn in dataset_names:\n",
    "    all_image_labels = [*all_image_labels, *readInAnnotations(fn)]\n",
    "\n",
    "# print(\"all_image_labels: {}\".format(all_image_labels))\n",
    "\n",
    "classes = set(all_image_labels)\n",
    "print(\"all classes (length={}): {}\".format(len(classes), classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f21c8c-b002-41c6-8ee5-8c249bc7f2aa",
   "metadata": {},
   "source": [
    "# Randomly split the dataset and corresponding labels into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44e9f9bb-0adf-4b24-8bb7-6607dccd3ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_images size: 6989\n",
      "training_labels length: 5591\n",
      "test_labels length: 1398\n",
      "counter: Counter({'Kangaroo': 870, 'Empty photo': 227, 'Emu': 119, 'Human Presense/Deployment': 110, 'Fox': 33, 'Cat': 16, 'Other': 16, 'Rabbit': 7})\n",
      "training_classes (length=8): ['Human Presense/Deployment', 'Empty photo', 'Emu', 'Kangaroo', 'Other', 'Rabbit', 'Fox', 'Cat']\n",
      "test_classes (length=8): ['Human Presense/Deployment', 'Kangaroo', 'Empty photo', 'Fox', 'Emu', 'Cat', 'Rabbit', 'Other']\n",
      "done stacking\n",
      "training_images shape: (5591, 224, 224, 3)\n",
      "test_images shape: (1398, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"all_images size: {}\".format(len(all_images)))\n",
    "# print(\"all_image_labels size: {}\".format(len(all_image_labels)))\n",
    "\n",
    "\n",
    "training_images, test_images, training_labels, test_labels = train_test_split(all_images, all_image_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"training_labels length: {}\".format(len(training_labels)))\n",
    "print(\"test_labels length: {}\".format(len(test_labels)))\n",
    "# print(\"test_labels: {}\".format(test_labels))\n",
    "counter = collections.Counter(test_labels)\n",
    "print(\"counter: {}\".format(counter))\n",
    "\n",
    "# training_classes = set(training_labels)\n",
    "training_classes = []\n",
    "for label in training_labels:\n",
    "    if label not in training_classes:\n",
    "        training_classes.append(label)\n",
    "# test_classes = set(test_labels)\n",
    "test_classes = []\n",
    "for label in test_labels:\n",
    "    if label not in test_classes:\n",
    "        test_classes.append(label)\n",
    "print(\"training_classes (length={}): {}\".format(len(training_classes), training_classes))\n",
    "print(\"test_classes (length={}): {}\".format(len(test_classes), test_classes))\n",
    "\n",
    "# integer-encode labels so they can be one-hot-encoded\n",
    "# https://stackoverflow.com/a/56227965/6476994\n",
    "label_encoder = LabelEncoder()\n",
    "training_labels = np.array(training_labels)\n",
    "training_labels = label_encoder.fit_transform(training_labels)\n",
    "test_labels = np.array(test_labels)\n",
    "test_labels = label_encoder.fit_transform(test_labels)\n",
    "\n",
    "\n",
    "# convert list of numpy arrays to numpy array of numpy arrays\n",
    "# https://stackoverflow.com/a/27516930/6476994\n",
    "training_images = np.stack(training_images, axis = 0)\n",
    "test_images = np.stack(test_images, axis = 0)\n",
    "\n",
    "print(\"done stacking\")\n",
    "print(\"training_images shape: {}\".format(training_images.shape))\n",
    "print(\"test_images shape: {}\".format(test_images.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de40603-e6cd-4c93-856c-eed237c3f7dc",
   "metadata": {},
   "source": [
    "# ZFNet\n",
    "\n",
    "Source: https://towardsdatascience.com/zfnet-an-explanation-of-paper-with-code-f1bd6752121d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da469ee2-ad90-402b-9b57-55a1388138e3",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d882d77-9109-494a-8c37-7ee3518adf8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-29 09:08:50.963811: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-29 09:08:50.967284: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-29 09:08:50.967474: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-29 09:08:50.967901: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-29 09:08:50.968335: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-29 09:08:50.968490: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-29 09:08:50.968625: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-29 09:08:51.279203: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-29 09:08:51.279374: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-29 09:08:51.279515: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-29 09:08:51.279635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5257 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070, pci bus id: 0000:2b:00.0, compute capability: 7.5\n",
      "2022-05-29 09:08:51.799374: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 3366408192 exceeds 10% of free system memory.\n",
      "/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "2022-05-29 09:08:54.591308: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2692644864 exceeds 10% of free system memory.\n",
      "2022-05-29 09:08:55.452247: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2692644864 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-29 09:08:56.959056: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2022-05-29 09:08:57.274513: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 10s 59ms/step - loss: 1.2465 - accuracy: 0.5890 - top_k_categorical_accuracy: 0.9712 - val_loss: 1.0945 - val_accuracy: 0.6032 - val_top_k_categorical_accuracy: 0.9839 - lr: 0.0100\n",
      "Epoch 2/90\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 1.0198 - accuracy: 0.6172 - top_k_categorical_accuracy: 0.9897 - val_loss: 0.9513 - val_accuracy: 0.6282 - val_top_k_categorical_accuracy: 0.9875 - lr: 0.0100\n",
      "Epoch 3/90\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 0.9486 - accuracy: 0.6391 - top_k_categorical_accuracy: 0.9899 - val_loss: 0.9202 - val_accuracy: 0.6524 - val_top_k_categorical_accuracy: 0.9893 - lr: 0.0100\n",
      "Epoch 4/90\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 0.8534 - accuracy: 0.6798 - top_k_categorical_accuracy: 0.9926 - val_loss: 0.8546 - val_accuracy: 0.6738 - val_top_k_categorical_accuracy: 0.9911 - lr: 0.0100\n",
      "Epoch 5/90\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 0.8039 - accuracy: 0.7086 - top_k_categorical_accuracy: 0.9935 - val_loss: 0.8032 - val_accuracy: 0.7140 - val_top_k_categorical_accuracy: 0.9920 - lr: 0.0100\n",
      "Epoch 6/90\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 0.7455 - accuracy: 0.7314 - top_k_categorical_accuracy: 0.9944 - val_loss: 0.8668 - val_accuracy: 0.6899 - val_top_k_categorical_accuracy: 0.9920 - lr: 0.0100\n",
      "Epoch 7/90\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 0.6486 - accuracy: 0.7589 - top_k_categorical_accuracy: 0.9953 - val_loss: 0.6363 - val_accuracy: 0.7811 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-03\n",
      "Epoch 8/90\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 0.5293 - accuracy: 0.8086 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5916 - val_accuracy: 0.8025 - val_top_k_categorical_accuracy: 0.9955 - lr: 1.0000e-03\n",
      "Epoch 9/90\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 0.4871 - accuracy: 0.8225 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5818 - val_accuracy: 0.8025 - val_top_k_categorical_accuracy: 0.9955 - lr: 1.0000e-03\n",
      "Epoch 10/90\n",
      "140/140 [==============================] - 7s 49ms/step - loss: 0.4586 - accuracy: 0.8354 - top_k_categorical_accuracy: 0.9987 - val_loss: 0.5533 - val_accuracy: 0.8132 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-03\n",
      "Epoch 11/90\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 0.4273 - accuracy: 0.8428 - top_k_categorical_accuracy: 0.9984 - val_loss: 0.5465 - val_accuracy: 0.8186 - val_top_k_categorical_accuracy: 0.9955 - lr: 1.0000e-03\n",
      "Epoch 12/90\n",
      "140/140 [==============================] - 7s 52ms/step - loss: 0.3992 - accuracy: 0.8540 - top_k_categorical_accuracy: 0.9991 - val_loss: 0.5245 - val_accuracy: 0.8266 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-03\n",
      "Epoch 13/90\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 0.3766 - accuracy: 0.8614 - top_k_categorical_accuracy: 0.9998 - val_loss: 0.4960 - val_accuracy: 0.8347 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-03\n",
      "Epoch 14/90\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 0.3482 - accuracy: 0.8701 - top_k_categorical_accuracy: 0.9996 - val_loss: 0.5048 - val_accuracy: 0.8356 - val_top_k_categorical_accuracy: 0.9973 - lr: 1.0000e-03\n",
      "Epoch 15/90\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 0.3179 - accuracy: 0.8828 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4857 - val_accuracy: 0.8409 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-04\n",
      "Epoch 16/90\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 0.2969 - accuracy: 0.8953 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4799 - val_accuracy: 0.8418 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-04\n",
      "Epoch 17/90\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 0.2914 - accuracy: 0.8992 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4758 - val_accuracy: 0.8454 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-04\n",
      "Epoch 18/90\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 0.2866 - accuracy: 0.8976 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4730 - val_accuracy: 0.8472 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-04\n",
      "Epoch 19/90\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 0.2824 - accuracy: 0.9005 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4736 - val_accuracy: 0.8445 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-04\n",
      "Epoch 20/90\n",
      "140/140 [==============================] - 7s 52ms/step - loss: 0.2761 - accuracy: 0.9050 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4718 - val_accuracy: 0.8463 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 21/90\n",
      "140/140 [==============================] - 7s 52ms/step - loss: 0.2756 - accuracy: 0.9059 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4716 - val_accuracy: 0.8472 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 22/90\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 0.2750 - accuracy: 0.9050 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4715 - val_accuracy: 0.8463 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 23/90\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 0.2746 - accuracy: 0.9054 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4715 - val_accuracy: 0.8463 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 24/90\n",
      "140/140 [==============================] - 7s 52ms/step - loss: 0.2742 - accuracy: 0.9061 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4713 - val_accuracy: 0.8472 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 25/90\n",
      "140/140 [==============================] - 7s 52ms/step - loss: 0.2738 - accuracy: 0.9054 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4714 - val_accuracy: 0.8472 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 26/90\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 0.2735 - accuracy: 0.9059 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4711 - val_accuracy: 0.8472 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 27/90\n",
      "140/140 [==============================] - 7s 52ms/step - loss: 0.2732 - accuracy: 0.9068 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4710 - val_accuracy: 0.8481 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 28/90\n",
      "140/140 [==============================] - 7s 52ms/step - loss: 0.2728 - accuracy: 0.9063 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4711 - val_accuracy: 0.8481 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 29/90\n",
      "140/140 [==============================] - 7s 52ms/step - loss: 0.2725 - accuracy: 0.9068 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4711 - val_accuracy: 0.8481 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 30/90\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 0.2721 - accuracy: 0.9070 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4709 - val_accuracy: 0.8490 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 31/90\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 0.2718 - accuracy: 0.9068 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4709 - val_accuracy: 0.8490 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 32/90\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 0.2715 - accuracy: 0.9065 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4706 - val_accuracy: 0.8490 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 33/90\n",
      "140/140 [==============================] - 7s 52ms/step - loss: 0.2711 - accuracy: 0.9070 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4707 - val_accuracy: 0.8481 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 34/90\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 0.2707 - accuracy: 0.9070 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4705 - val_accuracy: 0.8508 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 35/90\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 0.2704 - accuracy: 0.9079 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4704 - val_accuracy: 0.8499 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 36/90\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 0.2701 - accuracy: 0.9076 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4703 - val_accuracy: 0.8490 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 37/90\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 0.2698 - accuracy: 0.9079 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4702 - val_accuracy: 0.8490 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 38/90\n",
      "140/140 [==============================] - 7s 54ms/step - loss: 0.2695 - accuracy: 0.9079 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4702 - val_accuracy: 0.8517 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 39/90\n",
      "140/140 [==============================] - 7s 53ms/step - loss: 0.2692 - accuracy: 0.9081 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4700 - val_accuracy: 0.8508 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 40/90\n",
      "140/140 [==============================] - 7s 52ms/step - loss: 0.2689 - accuracy: 0.9081 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4701 - val_accuracy: 0.8508 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 41/90\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 0.2686 - accuracy: 0.9079 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4698 - val_accuracy: 0.8508 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 42/90\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 0.2682 - accuracy: 0.9076 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4698 - val_accuracy: 0.8517 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 43/90\n",
      "140/140 [==============================] - 7s 53ms/step - loss: 0.2679 - accuracy: 0.9072 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4695 - val_accuracy: 0.8508 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 44/90\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 0.2676 - accuracy: 0.9085 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4694 - val_accuracy: 0.8508 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 45/90\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 0.2673 - accuracy: 0.9088 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4692 - val_accuracy: 0.8508 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 46/90\n",
      "140/140 [==============================] - 7s 53ms/step - loss: 0.2669 - accuracy: 0.9079 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4691 - val_accuracy: 0.8508 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 47/90\n",
      "140/140 [==============================] - 7s 52ms/step - loss: 0.2666 - accuracy: 0.9079 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4691 - val_accuracy: 0.8508 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 48/90\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 0.2664 - accuracy: 0.9094 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4688 - val_accuracy: 0.8517 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 49/90\n",
      "140/140 [==============================] - 7s 52ms/step - loss: 0.2660 - accuracy: 0.9085 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4689 - val_accuracy: 0.8517 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 50/90\n",
      "140/140 [==============================] - 7s 53ms/step - loss: 0.2657 - accuracy: 0.9103 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4688 - val_accuracy: 0.8525 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 51/90\n",
      "140/140 [==============================] - 7s 53ms/step - loss: 0.2653 - accuracy: 0.9097 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4686 - val_accuracy: 0.8525 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 52/90\n",
      "140/140 [==============================] - 7s 52ms/step - loss: 0.2651 - accuracy: 0.9088 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4686 - val_accuracy: 0.8525 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 53/90\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 0.2648 - accuracy: 0.9097 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4686 - val_accuracy: 0.8525 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 54/90\n",
      "140/140 [==============================] - 7s 53ms/step - loss: 0.2644 - accuracy: 0.9103 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4685 - val_accuracy: 0.8525 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 55/90\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 0.2642 - accuracy: 0.9101 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4684 - val_accuracy: 0.8525 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 56/90\n",
      "140/140 [==============================] - 7s 52ms/step - loss: 0.2639 - accuracy: 0.9106 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4682 - val_accuracy: 0.8525 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 57/90\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 0.2636 - accuracy: 0.9112 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4681 - val_accuracy: 0.8525 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 58/90\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 0.2632 - accuracy: 0.9106 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4680 - val_accuracy: 0.8525 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 59/90\n",
      "140/140 [==============================] - 7s 52ms/step - loss: 0.2630 - accuracy: 0.9110 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4678 - val_accuracy: 0.8525 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 60/90\n",
      "140/140 [==============================] - 7s 52ms/step - loss: 0.2627 - accuracy: 0.9106 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4678 - val_accuracy: 0.8517 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 61/90\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 0.2624 - accuracy: 0.9114 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.8534 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 62/90\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 0.2620 - accuracy: 0.9108 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.8525 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 63/90\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 0.2618 - accuracy: 0.9117 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4674 - val_accuracy: 0.8525 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 64/90\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 0.2615 - accuracy: 0.9112 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4673 - val_accuracy: 0.8534 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 65/90\n",
      "140/140 [==============================] - 7s 53ms/step - loss: 0.2612 - accuracy: 0.9117 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4674 - val_accuracy: 0.8534 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 66/90\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 0.2609 - accuracy: 0.9117 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4673 - val_accuracy: 0.8525 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 67/90\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 0.2606 - accuracy: 0.9128 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4670 - val_accuracy: 0.8534 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 68/90\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 0.2603 - accuracy: 0.9128 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4671 - val_accuracy: 0.8517 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 69/90\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 0.2600 - accuracy: 0.9128 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4668 - val_accuracy: 0.8517 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 70/90\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 0.2597 - accuracy: 0.9126 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4670 - val_accuracy: 0.8525 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 71/90\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 0.2594 - accuracy: 0.9126 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4667 - val_accuracy: 0.8525 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 72/90\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 0.2591 - accuracy: 0.9128 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4666 - val_accuracy: 0.8525 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 73/90\n",
      "140/140 [==============================] - 7s 53ms/step - loss: 0.2588 - accuracy: 0.9119 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4665 - val_accuracy: 0.8525 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 74/90\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 0.2585 - accuracy: 0.9130 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4664 - val_accuracy: 0.8543 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 75/90\n",
      "140/140 [==============================] - 7s 53ms/step - loss: 0.2583 - accuracy: 0.9121 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4662 - val_accuracy: 0.8534 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 76/90\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 0.2580 - accuracy: 0.9123 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4660 - val_accuracy: 0.8534 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 77/90\n",
      "140/140 [==============================] - 7s 53ms/step - loss: 0.2577 - accuracy: 0.9132 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4661 - val_accuracy: 0.8534 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 78/90\n",
      "140/140 [==============================] - 7s 52ms/step - loss: 0.2574 - accuracy: 0.9137 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4659 - val_accuracy: 0.8534 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 79/90\n",
      "140/140 [==============================] - 7s 52ms/step - loss: 0.2571 - accuracy: 0.9132 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4660 - val_accuracy: 0.8525 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 80/90\n",
      "140/140 [==============================] - 7s 52ms/step - loss: 0.2569 - accuracy: 0.9137 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4658 - val_accuracy: 0.8543 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 81/90\n",
      "140/140 [==============================] - 7s 52ms/step - loss: 0.2566 - accuracy: 0.9135 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4655 - val_accuracy: 0.8543 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 82/90\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 0.2562 - accuracy: 0.9132 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4658 - val_accuracy: 0.8543 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 83/90\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 0.2559 - accuracy: 0.9137 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4656 - val_accuracy: 0.8534 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 84/90\n",
      "140/140 [==============================] - 7s 52ms/step - loss: 0.2557 - accuracy: 0.9135 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4655 - val_accuracy: 0.8543 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 85/90\n",
      "140/140 [==============================] - 7s 52ms/step - loss: 0.2554 - accuracy: 0.9135 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4655 - val_accuracy: 0.8543 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 86/90\n",
      "140/140 [==============================] - 7s 52ms/step - loss: 0.2551 - accuracy: 0.9137 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4651 - val_accuracy: 0.8543 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 87/90\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 0.2548 - accuracy: 0.9139 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4652 - val_accuracy: 0.8552 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 88/90\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 0.2545 - accuracy: 0.9137 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4650 - val_accuracy: 0.8552 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 89/90\n",
      "140/140 [==============================] - 7s 53ms/step - loss: 0.2542 - accuracy: 0.9148 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4647 - val_accuracy: 0.8543 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 90/90\n",
      "140/140 [==============================] - 7s 53ms/step - loss: 0.2540 - accuracy: 0.9141 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4649 - val_accuracy: 0.8543 - val_top_k_categorical_accuracy: 0.9964 - lr: 1.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd3c830ba60>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training_images = tf.map_fn(lambda i: tf.stack([i]*3, axis=-1), training_images).numpy()\n",
    "# test_images = tf.map_fn(lambda i: tf.stack([i]*3, axis=-1), test_images).numpy()\n",
    "\n",
    "training_images = tf.image.resize(training_images, [224, 224]).numpy()\n",
    "test_images = tf.image.resize(test_images, [224, 224]).numpy()\n",
    "\n",
    "training_images = training_images.reshape(training_images.shape)\n",
    "training_images = training_images / 255.0\n",
    "test_images = test_images.reshape(test_images.shape)\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "training_labels = tf.keras.utils.to_categorical(training_labels, num_classes=len(training_classes))\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=len(test_classes))\n",
    "\n",
    "num_len_train = int(0.8 * len(training_images))\n",
    "\n",
    "ttraining_images = training_images[:num_len_train]\n",
    "ttraining_labels = training_labels[:num_len_train]\n",
    "\n",
    "valid_images = training_images[num_len_train:]\n",
    "valid_labels = training_labels[num_len_train:]\n",
    "\n",
    "training_images = ttraining_images\n",
    "training_labels = ttraining_labels\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "                                    \n",
    "\t\ttf.keras.layers.Conv2D(96, (7, 7), strides=(2, 2), activation='relu',\n",
    "\t\t\tinput_shape=(224, 224, 3)),\n",
    "\t\ttf.keras.layers.MaxPooling2D(3, strides=2),\n",
    "    tf.keras.layers.Lambda(lambda x: tf.image.per_image_standardization(x)),\n",
    "\n",
    "\t\ttf.keras.layers.Conv2D(256, (5, 5), strides=(2, 2), activation='relu'),\n",
    "\t\ttf.keras.layers.MaxPooling2D(3, strides=2),\n",
    "    tf.keras.layers.Lambda(lambda x: tf.image.per_image_standardization(x)),\n",
    "\n",
    "\t\ttf.keras.layers.Conv2D(384, (3, 3), activation='relu'),\n",
    "\n",
    "\t\ttf.keras.layers.Conv2D(384, (3, 3), activation='relu'),\n",
    "\n",
    "\t\ttf.keras.layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "\n",
    "\t\ttf.keras.layers.MaxPooling2D(3, strides=2),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "\n",
    "\t\ttf.keras.layers.Dense(4096),\n",
    "\n",
    "\t\ttf.keras.layers.Dense(4096),\n",
    "\n",
    "\t\ttf.keras.layers.Dense(len(classes), activation='softmax')#FIXME is this the number of classes? (check paper)\n",
    "\t])\n",
    "\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.01, momentum=0.9), \\\n",
    "              loss='categorical_crossentropy', \\\n",
    "              metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(5)])\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', \\\n",
    "                                            \t\tfactor=0.1, patience=1, \\\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tmin_lr=0.00001)\n",
    "model.fit(training_images, training_labels, batch_size=32, \\\n",
    "          validation_data=(valid_images, valid_labels), \\\n",
    "\t\t\t\t\tepochs=90, callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d43d1c-41ee-45f0-a341-3d2757eb5a12",
   "metadata": {},
   "source": [
    "## Evaluate the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7c21960-4a3d-46cb-8dfd-d3b8a8314ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_images shape: (1398, 224, 224, 3)\n",
      "test_labels shape: (1398, 8)\n",
      "44/44 [==============================] - 1s 21ms/step - loss: 0.4615 - accuracy: 0.8584 - top_k_categorical_accuracy: 0.9971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-29 09:19:47.945218: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 698.12MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-05-29 09:19:47.945246: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 698.12MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    }
   ],
   "source": [
    "print('test_images shape: {}'.format(test_images.shape))\n",
    "print('test_labels shape: {}'.format(test_labels.shape))\n",
    "\n",
    "results = model.evaluate(test_images,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18b52e25-9d06-4e81-b6c7-d317e158b35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-29 09:19:58.190816: W tensorflow/core/common_runtime/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 802.76MiB (rounded to 841752576)requested by op _EagerConst\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2022-05-29 09:19:58.190847: I tensorflow/core/common_runtime/bfc_allocator.cc:1027] BFCAllocator dump for GPU_0_bfc\n",
      "2022-05-29 09:19:58.190858: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (256): \tTotal Chunks: 41, Chunks in use: 41. 10.2KiB allocated for chunks. 10.2KiB in use in bin. 260B client-requested in use in bin.\n",
      "2022-05-29 09:19:58.190866: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (512): \tTotal Chunks: 2, Chunks in use: 2. 1.0KiB allocated for chunks. 1.0KiB in use in bin. 768B client-requested in use in bin.\n",
      "2022-05-29 09:19:58.190874: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (1024): \tTotal Chunks: 10, Chunks in use: 9. 12.2KiB allocated for chunks. 11.2KiB in use in bin. 11.0KiB client-requested in use in bin.\n",
      "2022-05-29 09:19:58.190880: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-05-29 09:19:58.190887: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-05-29 09:19:58.190893: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-05-29 09:19:58.190901: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (16384): \tTotal Chunks: 4, Chunks in use: 4. 64.0KiB allocated for chunks. 64.0KiB in use in bin. 64.0KiB client-requested in use in bin.\n",
      "2022-05-29 09:19:58.190909: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (32768): \tTotal Chunks: 3, Chunks in use: 3. 134.0KiB allocated for chunks. 134.0KiB in use in bin. 133.8KiB client-requested in use in bin.\n",
      "2022-05-29 09:19:58.190916: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (65536): \tTotal Chunks: 1, Chunks in use: 1. 66.8KiB allocated for chunks. 66.8KiB in use in bin. 55.1KiB client-requested in use in bin.\n",
      "2022-05-29 09:19:58.190924: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (131072): \tTotal Chunks: 2, Chunks in use: 2. 256.0KiB allocated for chunks. 256.0KiB in use in bin. 256.0KiB client-requested in use in bin.\n",
      "2022-05-29 09:19:58.190931: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (262144): \tTotal Chunks: 1, Chunks in use: 1. 256.0KiB allocated for chunks. 256.0KiB in use in bin. 139.8KiB client-requested in use in bin.\n",
      "2022-05-29 09:19:58.190937: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-05-29 09:19:58.190943: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-05-29 09:19:58.190951: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (2097152): \tTotal Chunks: 5, Chunks in use: 5. 15.47MiB allocated for chunks. 15.47MiB in use in bin. 14.81MiB client-requested in use in bin.\n",
      "2022-05-29 09:19:58.190959: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (4194304): \tTotal Chunks: 4, Chunks in use: 3. 21.19MiB allocated for chunks. 16.50MiB in use in bin. 13.50MiB client-requested in use in bin.\n",
      "2022-05-29 09:19:58.190965: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-05-29 09:19:58.190972: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (16777216): \tTotal Chunks: 3, Chunks in use: 2. 76.60MiB allocated for chunks. 44.62MiB in use in bin. 32.00MiB client-requested in use in bin.\n",
      "2022-05-29 09:19:58.190978: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-05-29 09:19:58.190988: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (67108864): \tTotal Chunks: 2, Chunks in use: 2. 191.98MiB allocated for chunks. 191.98MiB in use in bin. 128.00MiB client-requested in use in bin.\n",
      "2022-05-29 09:19:58.190994: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-05-29 09:19:58.191001: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (268435456): \tTotal Chunks: 5, Chunks in use: 3. 4.83GiB allocated for chunks. 3.92GiB in use in bin. 3.92GiB client-requested in use in bin.\n",
      "2022-05-29 09:19:58.191009: I tensorflow/core/common_runtime/bfc_allocator.cc:1050] Bin for 802.76MiB was 256.00MiB, Chunk State: \n",
      "2022-05-29 09:19:58.191021: I tensorflow/core/common_runtime/bfc_allocator.cc:1056]   Size: 441.54MiB | Requested Size: 40.75MiB | in_use: 0 | bin_num: 20, prev:   Size: 802.76MiB | Requested Size: 802.76MiB | in_use: 1 | bin_num: -1\n",
      "2022-05-29 09:19:58.191032: I tensorflow/core/common_runtime/bfc_allocator.cc:1056]   Size: 496.59MiB | Requested Size: 482.44MiB | in_use: 0 | bin_num: 20, prev:   Size: 256B | Requested Size: 8B | in_use: 1 | bin_num: -1, next:   Size: 1.2KiB | Requested Size: 1.0KiB | in_use: 1 | bin_num: -1\n",
      "2022-05-29 09:19:58.191037: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] Next region of size 5512757248\n",
      "2022-05-29 09:19:58.191045: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd12e000000 of size 256 next 3\n",
      "2022-05-29 09:19:58.191053: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd12e000100 of size 256 next 4\n",
      "2022-05-29 09:19:58.191058: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd12e000200 of size 256 next 5\n",
      "2022-05-29 09:19:58.191063: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd12e000300 of size 256 next 6\n",
      "2022-05-29 09:19:58.191068: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd12e000400 of size 512 next 7\n",
      "2022-05-29 09:19:58.191073: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd12e000600 of size 256 next 10\n",
      "2022-05-29 09:19:58.191078: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd12e000700 of size 256 next 11\n",
      "2022-05-29 09:19:58.191084: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd12e000800 of size 1024 next 12\n",
      "2022-05-29 09:19:58.191089: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd12e000c00 of size 256 next 15\n",
      "2022-05-29 09:19:58.191094: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd12e000d00 of size 256 next 16\n",
      "2022-05-29 09:19:58.191099: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd12e000e00 of size 1536 next 19\n",
      "2022-05-29 09:19:58.191104: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd12e001400 of size 256 next 20\n",
      "2022-05-29 09:19:58.191109: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd12e001500 of size 256 next 21\n",
      "2022-05-29 09:19:58.191114: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd12e001600 of size 1536 next 22\n",
      "2022-05-29 09:19:58.191119: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd12e001c00 of size 1024 next 26\n",
      "2022-05-29 09:19:58.191124: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd12e002000 of size 256 next 27\n",
      "2022-05-29 09:19:58.191129: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd12e002100 of size 256 next 28\n",
      "2022-05-29 09:19:58.191134: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd12e002200 of size 16384 next 29\n",
      "2022-05-29 09:19:58.191139: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd12e006200 of size 256 next 32\n",
      "2022-05-29 09:19:58.191144: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd12e006300 of size 256 next 33\n",
      "2022-05-29 09:19:58.191152: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd12e006400 of size 16384 next 34\n",
      "2022-05-29 09:19:58.191157: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd12e00a400 of size 256 next 37\n",
      "2022-05-29 09:19:58.191162: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd12e00a500 of size 256 next 38\n",
      "2022-05-29 09:19:58.191167: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd12e00a600 of size 256 next 39\n",
      "2022-05-29 09:19:58.191172: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd12e00a700 of size 256 next 42\n",
      "2022-05-29 09:19:58.191177: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd12e00a800 of size 256 next 43\n",
      "2022-05-29 09:19:58.191182: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd12e00a900 of size 256 next 93\n",
      "2022-05-29 09:19:58.191187: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd12e00aa00 of size 256 next 45\n",
      "2022-05-29 09:19:58.191192: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd12e00ab00 of size 256 next 46\n",
      "2022-05-29 09:19:58.191197: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd12e00ac00 of size 256 next 48\n",
      "2022-05-29 09:19:58.191202: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd12e00ad00 of size 256 next 49\n",
      "2022-05-29 09:19:58.191207: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd12e00ae00 of size 256 next 50\n",
      "2022-05-29 09:19:58.191212: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd12e00af00 of size 256 next 51\n",
      "2022-05-29 09:19:58.191217: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd12e00b000 of size 256 next 52\n",
      "2022-05-29 09:19:58.191222: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd12e00b100 of size 256 next 53\n",
      "2022-05-29 09:19:58.191227: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd12e00b200 of size 256 next 54\n",
      "2022-05-29 09:19:58.191232: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd12e00b300 of size 68352 next 8\n",
      "2022-05-29 09:19:58.191238: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd12e01be00 of size 56576 next 9\n",
      "2022-05-29 09:19:58.191243: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd12e029b00 of size 1024 next 56\n",
      "2022-05-29 09:19:58.191248: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd12e029f00 of size 4914176 next 14\n",
      "2022-05-29 09:19:58.191254: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd12e4d9b00 of size 2457600 next 13\n",
      "2022-05-29 09:19:58.191260: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd12e731b00 of size 262144 next 41\n",
      "2022-05-29 09:19:58.191266: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd12e771b00 of size 131072 next 40\n",
      "2022-05-29 09:19:58.191271: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd12e791b00 of size 512 next 55\n",
      "2022-05-29 09:19:58.191276: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd12e791d00 of size 3145216 next 18\n",
      "2022-05-29 09:19:58.191281: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd12ea91b00 of size 3538944 next 17\n",
      "2022-05-29 09:19:58.191286: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd12edf1b00 of size 3538944 next 25\n",
      "2022-05-29 09:19:58.191291: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd12f151b00 of size 1536 next 57\n",
      "2022-05-29 09:19:58.191297: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd12f152100 of size 7076352 next 24\n",
      "2022-05-29 09:19:58.191302: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd12f811b00 of size 5308416 next 23\n",
      "2022-05-29 09:19:58.191307: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd12fd21b00 of size 1536 next 58\n",
      "2022-05-29 09:19:58.191312: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd12fd22100 of size 3538944 next 59\n",
      "2022-05-29 09:19:58.191318: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd130082100 of size 1024 next 60\n",
      "2022-05-29 09:19:58.191323: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd130082500 of size 30012928 next 31\n",
      "2022-05-29 09:19:58.191328: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd131d21b00 of size 16777216 next 30\n",
      "2022-05-29 09:19:58.191335: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd132d21b00 of size 16384 next 61\n",
      "2022-05-29 09:19:58.191340: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd132d25b00 of size 134201344 next 36\n",
      "2022-05-29 09:19:58.191345: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd13ad21b00 of size 67108864 next 35\n",
      "2022-05-29 09:19:58.191350: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd13ed21b00 of size 16384 next 62\n",
      "2022-05-29 09:19:58.191355: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd13ed25b00 of size 131072 next 63\n",
      "2022-05-29 09:19:58.191360: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd13ed45b00 of size 256 next 64\n",
      "2022-05-29 09:19:58.191365: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd13ed45c00 of size 256 next 74\n",
      "2022-05-29 09:19:58.191370: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd13ed45d00 of size 256 next 66\n",
      "2022-05-29 09:19:58.191375: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd13ed45e00 of size 256 next 67\n",
      "2022-05-29 09:19:58.191380: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd13ed45f00 of size 256 next 68\n",
      "2022-05-29 09:19:58.191385: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd13ed46000 of size 256 next 69\n",
      "2022-05-29 09:19:58.191390: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd13ed46100 of size 256 next 70\n",
      "2022-05-29 09:19:58.191395: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd13ed46200 of size 256 next 71\n",
      "2022-05-29 09:19:58.191400: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7fd13ed46300 of size 33532416 next 114\n",
      "2022-05-29 09:19:58.191405: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd140d40d00 of size 35840 next 110\n",
      "2022-05-29 09:19:58.191411: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd140d49900 of size 256 next 116\n",
      "2022-05-29 09:19:58.191416: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd140d49a00 of size 256 next 105\n",
      "2022-05-29 09:19:58.191421: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd140d49b00 of size 256 next 90\n",
      "2022-05-29 09:19:58.191426: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7fd140d49c00 of size 1024 next 117\n",
      "2022-05-29 09:19:58.191431: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd140d4a000 of size 44800 next 99\n",
      "2022-05-29 09:19:58.191436: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7fd140d54f00 of size 4921856 next 76\n",
      "2022-05-29 09:19:58.191441: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd141206900 of size 256 next 77\n",
      "2022-05-29 09:19:58.191446: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7fd141206a00 of size 520710656 next 1\n",
      "2022-05-29 09:19:58.191451: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd16029d400 of size 1280 next 2\n",
      "2022-05-29 09:19:58.191456: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd16029d900 of size 2692644864 next 47\n",
      "2022-05-29 09:19:58.191462: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd200a85900 of size 673763328 next 108\n",
      "2022-05-29 09:19:58.191467: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7fd228d12900 of size 841752576 next 100\n",
      "2022-05-29 09:19:58.191473: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7fd25afd4900 of size 462993152 next 18446744073709551615\n",
      "2022-05-29 09:19:58.191479: I tensorflow/core/common_runtime/bfc_allocator.cc:1088]      Summary of in-use Chunks by size: \n",
      "2022-05-29 09:19:58.191486: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 41 Chunks of size 256 totalling 10.2KiB\n",
      "2022-05-29 09:19:58.191492: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 2 Chunks of size 512 totalling 1.0KiB\n",
      "2022-05-29 09:19:58.191498: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 4 Chunks of size 1024 totalling 4.0KiB\n",
      "2022-05-29 09:19:58.191504: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2022-05-29 09:19:58.191509: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 4 Chunks of size 1536 totalling 6.0KiB\n",
      "2022-05-29 09:19:58.191515: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 4 Chunks of size 16384 totalling 64.0KiB\n",
      "2022-05-29 09:19:58.191521: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 35840 totalling 35.0KiB\n",
      "2022-05-29 09:19:58.191527: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 44800 totalling 43.8KiB\n",
      "2022-05-29 09:19:58.191533: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 56576 totalling 55.2KiB\n",
      "2022-05-29 09:19:58.191539: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 68352 totalling 66.8KiB\n",
      "2022-05-29 09:19:58.191545: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 2 Chunks of size 131072 totalling 256.0KiB\n",
      "2022-05-29 09:19:58.191551: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 262144 totalling 256.0KiB\n",
      "2022-05-29 09:19:58.191557: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 2457600 totalling 2.34MiB\n",
      "2022-05-29 09:19:58.191562: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 3145216 totalling 3.00MiB\n",
      "2022-05-29 09:19:58.191568: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 3 Chunks of size 3538944 totalling 10.12MiB\n",
      "2022-05-29 09:19:58.191574: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 4914176 totalling 4.69MiB\n",
      "2022-05-29 09:19:58.191580: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 5308416 totalling 5.06MiB\n",
      "2022-05-29 09:19:58.191585: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 7076352 totalling 6.75MiB\n",
      "2022-05-29 09:19:58.191591: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 16777216 totalling 16.00MiB\n",
      "2022-05-29 09:19:58.191597: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 30012928 totalling 28.62MiB\n",
      "2022-05-29 09:19:58.191603: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 67108864 totalling 64.00MiB\n",
      "2022-05-29 09:19:58.191609: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 134201344 totalling 127.98MiB\n",
      "2022-05-29 09:19:58.191615: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 673763328 totalling 642.55MiB\n",
      "2022-05-29 09:19:58.191621: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 841752576 totalling 802.76MiB\n",
      "2022-05-29 09:19:58.191627: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 2692644864 totalling 2.51GiB\n",
      "2022-05-29 09:19:58.191632: I tensorflow/core/common_runtime/bfc_allocator.cc:1095] Sum Total of in-use chunks: 4.18GiB\n",
      "2022-05-29 09:19:58.191638: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] total_region_allocated_bytes_: 5512757248 memory_limit_: 5512757248 available bytes: 0 curr_region_allocation_bytes_: 11025514496\n",
      "2022-05-29 09:19:58.191647: I tensorflow/core/common_runtime/bfc_allocator.cc:1103] Stats: \n",
      "Limit:                      5512757248\n",
      "InUse:                      4490598144\n",
      "MaxInUse:                   5049764096\n",
      "NumAllocs:                     2512190\n",
      "MaxAllocSize:               2692644864\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2022-05-29 09:19:58.191658: W tensorflow/core/common_runtime/bfc_allocator.cc:491] ******_________*****************************************************************************________\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m predictions \u001b[38;5;241m=\u001b[39m (\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_images\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint32\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "predictions = (model.predict(test_images) > 0.5).astype(\"int32\")\n",
    "# print(\"Predictions (shape: {}):\\n{}\".format(predictions.shape, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a2dd7f-3232-4b86-84e0-4e4b7137660b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"test_classes: {}\".format(test_classes))\n",
    "# classification_report uses alphabetic ordering of the classes, so to match the encoded labels to the target_names, provide a sortest list of classes\n",
    "# https://stackoverflow.com/a/48495303\n",
    "sorted_test_classes = sorted(test_classes)\n",
    "print(classification_report(test_labels, predictions, target_names=sorted_test_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738305b2-92f1-41c1-a4f2-07171823ec10",
   "metadata": {},
   "source": [
    "# Save the model\n",
    "* use the current date/time so we can keep incrementation progress of the model as we re-run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e4681e-b9b8-419c-9cd5-bfd3b0a1763f",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "dt_string = now.strftime('%d-%m-%Y_%H:%M:%S')\n",
    "print(\"saving model as: 'ZFNet-{}.h5'.'\".format(dt_string))\n",
    "\n",
    "model.save('ZFNet-{}.h5'.format(dt_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006c0524-22ef-4ad4-8403-faec5dc9f5f4",
   "metadata": {},
   "source": [
    "## Free up the GPU's memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4c59ac-35fd-420c-ab71-2dc2c7c457ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda.select_device(0)\n",
    "cuda.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
