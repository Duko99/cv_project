{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ad62cb3-b86d-4a0a-8492-ef09608a4c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import imageio as iio\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from numba import cuda  # https://stackoverflow.com/a/52354865/6476994\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c4a177c-422b-48b4-b51f-ac05542a4e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# allows all images to be displayed at once (else only displays the last call to plt.imshow())\n",
    "# https://stackoverflow.com/a/41210974\n",
    "def displayImage(image, caption = None, colour = None) -> None:\n",
    "    plt.figure()\n",
    "    if(colour != None):\n",
    "        plt.imshow(image, cmap=colour)\n",
    "    else:\n",
    "        plt.imshow(image)\n",
    "        \n",
    "    if(caption != None):\n",
    "        # display caption below picture (https://stackoverflow.com/a/51486361)\n",
    "        plt.figtext(0.5, 0.01, caption, wrap=True, horizontalalignment='center', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486d3892-4189-4e6a-bfee-0309e96d0b39",
   "metadata": {},
   "source": [
    "# ZFNet\n",
    "\n",
    "Source: https://towardsdatascience.com/zfnet-an-explanation-of-paper-with-code-f1bd6752121d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2162b806-d6bd-47ba-acc3-3f7209a27997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# free up GPU\n",
    "cuda.select_device(0)\n",
    "cuda.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b197fb12-a89b-4f03-a28c-ca0cb72b9e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist = tf.keras.datasets.mnist\n",
    "# (training_images, training_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfbb46df-237c-4f68-b1af-5ee75f6b69b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the all original output filenames\n",
    "# https://stackoverflow.com/a/3207973\n",
    "all_image_filenames = next(os.walk('data/BB01'),\n",
    "                     (None, None, []))[2]  # [] if no file\n",
    "all_image_filenames.sort()\n",
    "\n",
    "# split files into two groups\n",
    "# training_images_filenames = all_image_filenames[:len(all_image_filenames)//2]\n",
    "# test_images_filenames = all_image_filenames[len(all_image_filenames)//2:]\n",
    "training_images_filenames = all_image_filenames[0:200]\n",
    "test_images_filenames = all_image_filenames[201:285]\n",
    "\n",
    "training_images = []\n",
    "for train_img_fn in training_images_filenames:\n",
    "    im = Image.open('data/BB01/{}'.format(train_img_fn))\n",
    "    training_images.append(np.asarray(im))\n",
    "# convert list of numpy arrays to numpy array of numpy arrays\n",
    "# https://stackoverflow.com/a/27516930/6476994\n",
    "training_images = np.stack(training_images, axis=0)\n",
    "    \n",
    "test_images = []\n",
    "for test_img_fn in test_images_filenames:\n",
    "    im = Image.open('data/BB01/{}'.format(test_img_fn))\n",
    "    test_images.append(np.asarray(im))\n",
    "test_images = np.stack(test_images, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86aa9b8b-eb63-496d-ab41-a275503ede2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "all_annotations_filenames = next(os.walk('annotations/BB01'),\n",
    "                     (None, None, []))[2]  # [] if no file\n",
    "all_annotations_filenames.sort()\n",
    "\n",
    "# split files into two groups\n",
    "# training_annotations_filenames = all_annotations_filenames[:len(all_annotations_filenames)//2]\n",
    "# test_annotations_filenames = all_annotations_filenames[len(all_annotations_filenames)//2:]\n",
    "training_annotations_filenames = all_annotations_filenames[0:200]\n",
    "test_annotations_filenames = all_annotations_filenames[201:285]\n",
    "\n",
    "training_labels = []\n",
    "for train_ann_filename in training_annotations_filenames:\n",
    "    # https://www.geeksforgeeks.org/reading-and-writing-xml-files-in-python/#:~:text=To%20read%20an%20XML%20file,xml%20file%20using%20getroot().\n",
    "    tree = ET.parse('annotations/BB01/{}'.format(train_ann_filename))\n",
    "    root = tree.getroot()\n",
    "    try:\n",
    "        training_labels.append(root[6][0].text)\n",
    "    except:\n",
    "        training_labels.append('none')\n",
    "# integer-encode labels so they can be one-hot-encoded\n",
    "# https://stackoverflow.com/a/56227965/6476994\n",
    "training_labels = np.array(training_labels)\n",
    "training_labels = label_encoder.fit_transform(training_labels)\n",
    "\n",
    "\n",
    "test_labels = []\n",
    "for test_ann_filename in test_annotations_filenames:\n",
    "    tree = ET.parse('annotations/BB01/{}'.format(test_ann_filename))\n",
    "    root = tree.getroot()\n",
    "    try:\n",
    "        test_labels.append(root[6][0].text)\n",
    "    except:\n",
    "        test_labels.append('none')\n",
    "# integer-encode labels so they can be one-hot-encoded\n",
    "test_labels = np.array(test_labels)\n",
    "test_labels = label_encoder.fit_transform(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da469ee2-ad90-402b-9b57-55a1388138e3",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d882d77-9109-494a-8c37-7ee3518adf8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-17 15:20:44.659948: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-17 15:20:44.685917: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-17 15:20:44.686100: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-17 15:20:44.686784: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-17 15:20:44.687225: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-17 15:20:44.687371: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-17 15:20:44.687500: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-17 15:20:44.943900: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-17 15:20:44.944074: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-17 15:20:44.944213: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-17 15:20:44.944336: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5279 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070, pci bus id: 0000:2b:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luke/.local/lib/python3.9/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "2022-05-17 15:20:47.177021: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8400\n",
      "2022-05-17 15:20:47.617506: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step - loss: 2.5260 - accuracy: 0.0714 - top_k_categorical_accuracy: 0.5000 - val_loss: 2.5480 - val_accuracy: 0.5862 - val_top_k_categorical_accuracy: 0.8966 - lr: 0.0100\n",
      "Epoch 2/90\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.8821 - accuracy: 0.5000 - top_k_categorical_accuracy: 0.9048 - val_loss: 1.8899 - val_accuracy: 0.2069 - val_top_k_categorical_accuracy: 0.8966 - lr: 0.0100\n",
      "Epoch 3/90\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 1.7456 - accuracy: 0.2500 - top_k_categorical_accuracy: 0.9762 - val_loss: 2.0311 - val_accuracy: 0.5862 - val_top_k_categorical_accuracy: 0.8966 - lr: 0.0100\n",
      "Epoch 4/90\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.1878 - accuracy: 0.5000 - top_k_categorical_accuracy: 0.9762 - val_loss: 2.9895 - val_accuracy: 0.5862 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-03\n",
      "Epoch 5/90\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 3.2403 - accuracy: 0.5000 - top_k_categorical_accuracy: 0.9762 - val_loss: 3.6471 - val_accuracy: 0.5862 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-04\n",
      "Epoch 6/90\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 3.9360 - accuracy: 0.5000 - top_k_categorical_accuracy: 0.9762 - val_loss: 4.2190 - val_accuracy: 0.5862 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 7/90\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 4.5358 - accuracy: 0.5000 - top_k_categorical_accuracy: 0.9762 - val_loss: 4.7436 - val_accuracy: 0.5862 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 8/90\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 5.0925 - accuracy: 0.5000 - top_k_categorical_accuracy: 0.9762 - val_loss: 5.2324 - val_accuracy: 0.5862 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 9/90\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 5.6080 - accuracy: 0.5000 - top_k_categorical_accuracy: 0.9762 - val_loss: 5.6733 - val_accuracy: 0.5862 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 10/90\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 6.0491 - accuracy: 0.5000 - top_k_categorical_accuracy: 0.9762 - val_loss: 6.0470 - val_accuracy: 0.5862 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 11/90\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 6.4112 - accuracy: 0.5000 - top_k_categorical_accuracy: 0.9762 - val_loss: 6.3306 - val_accuracy: 0.5862 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 12/90\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 6.6665 - accuracy: 0.5000 - top_k_categorical_accuracy: 0.9762 - val_loss: 6.5063 - val_accuracy: 0.5862 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 13/90\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 6.8018 - accuracy: 0.5000 - top_k_categorical_accuracy: 0.9762 - val_loss: 6.5739 - val_accuracy: 0.5862 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 14/90\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 6.8111 - accuracy: 0.5000 - top_k_categorical_accuracy: 0.9762 - val_loss: 6.5275 - val_accuracy: 0.5862 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 15/90\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 6.6813 - accuracy: 0.5000 - top_k_categorical_accuracy: 0.9762 - val_loss: 6.3592 - val_accuracy: 0.5862 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 16/90\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 6.4043 - accuracy: 0.5000 - top_k_categorical_accuracy: 0.9762 - val_loss: 6.0670 - val_accuracy: 0.5862 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 17/90\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 5.9731 - accuracy: 0.5000 - top_k_categorical_accuracy: 0.9762 - val_loss: 5.6523 - val_accuracy: 0.5862 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 18/90\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 5.3912 - accuracy: 0.5000 - top_k_categorical_accuracy: 0.9762 - val_loss: 5.1202 - val_accuracy: 0.5862 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 19/90\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 4.6705 - accuracy: 0.5000 - top_k_categorical_accuracy: 0.9762 - val_loss: 4.5094 - val_accuracy: 0.5862 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 20/90\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 3.8518 - accuracy: 0.5000 - top_k_categorical_accuracy: 0.9762 - val_loss: 4.0007 - val_accuracy: 0.5862 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 21/90\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 3.1005 - accuracy: 0.5119 - top_k_categorical_accuracy: 0.9762 - val_loss: 4.0097 - val_accuracy: 0.2586 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 22/90\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.8041 - accuracy: 0.4524 - top_k_categorical_accuracy: 0.9762 - val_loss: 4.5936 - val_accuracy: 0.1638 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 23/90\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 3.1143 - accuracy: 0.2619 - top_k_categorical_accuracy: 0.9762 - val_loss: 5.2262 - val_accuracy: 0.1034 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 24/90\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 3.5782 - accuracy: 0.1548 - top_k_categorical_accuracy: 0.9762 - val_loss: 5.6046 - val_accuracy: 0.1034 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 25/90\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 3.8470 - accuracy: 0.1667 - top_k_categorical_accuracy: 0.9762 - val_loss: 5.6609 - val_accuracy: 0.1034 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 26/90\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 3.8645 - accuracy: 0.2262 - top_k_categorical_accuracy: 0.9762 - val_loss: 5.4006 - val_accuracy: 0.2586 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 27/90\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 3.6368 - accuracy: 0.2262 - top_k_categorical_accuracy: 0.9762 - val_loss: 4.8645 - val_accuracy: 0.2586 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 28/90\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 3.1912 - accuracy: 0.3095 - top_k_categorical_accuracy: 0.9762 - val_loss: 4.1316 - val_accuracy: 0.2759 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 29/90\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.6024 - accuracy: 0.3690 - top_k_categorical_accuracy: 0.9762 - val_loss: 3.4060 - val_accuracy: 0.3879 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 30/90\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 2.0860 - accuracy: 0.5714 - top_k_categorical_accuracy: 0.9762 - val_loss: 3.0043 - val_accuracy: 0.6897 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 31/90\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 1.8648 - accuracy: 0.7143 - top_k_categorical_accuracy: 0.9762 - val_loss: 2.9783 - val_accuracy: 0.7155 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 32/90\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 1.9110 - accuracy: 0.5952 - top_k_categorical_accuracy: 0.9762 - val_loss: 3.0911 - val_accuracy: 0.5603 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 33/90\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.0603 - accuracy: 0.4643 - top_k_categorical_accuracy: 0.9762 - val_loss: 3.1879 - val_accuracy: 0.5603 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 34/90\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.1804 - accuracy: 0.4643 - top_k_categorical_accuracy: 0.9762 - val_loss: 3.2190 - val_accuracy: 0.5603 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 35/90\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.2243 - accuracy: 0.4643 - top_k_categorical_accuracy: 0.9762 - val_loss: 3.1872 - val_accuracy: 0.5603 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 36/90\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 2.1947 - accuracy: 0.4643 - top_k_categorical_accuracy: 0.9762 - val_loss: 3.1099 - val_accuracy: 0.7155 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 37/90\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 2.1113 - accuracy: 0.5833 - top_k_categorical_accuracy: 0.9762 - val_loss: 3.0102 - val_accuracy: 0.7155 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 38/90\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 2.0031 - accuracy: 0.6071 - top_k_categorical_accuracy: 0.9762 - val_loss: 2.9072 - val_accuracy: 0.7155 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 39/90\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 1.8960 - accuracy: 0.6190 - top_k_categorical_accuracy: 0.9762 - val_loss: 2.8127 - val_accuracy: 0.7155 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 40/90\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 1.8068 - accuracy: 0.6429 - top_k_categorical_accuracy: 0.9762 - val_loss: 2.7332 - val_accuracy: 0.7155 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 41/90\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 1.7415 - accuracy: 0.6429 - top_k_categorical_accuracy: 0.9762 - val_loss: 2.6744 - val_accuracy: 0.7155 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 42/90\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 1.6992 - accuracy: 0.6429 - top_k_categorical_accuracy: 0.9762 - val_loss: 2.6398 - val_accuracy: 0.7155 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 43/90\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 1.6755 - accuracy: 0.7500 - top_k_categorical_accuracy: 0.9762 - val_loss: 2.6266 - val_accuracy: 0.7069 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 44/90\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 1.6638 - accuracy: 0.7500 - top_k_categorical_accuracy: 0.9762 - val_loss: 2.6255 - val_accuracy: 0.6897 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 45/90\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 1.6555 - accuracy: 0.7500 - top_k_categorical_accuracy: 0.9762 - val_loss: 2.6231 - val_accuracy: 0.5690 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 46/90\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 1.6409 - accuracy: 0.7381 - top_k_categorical_accuracy: 0.9762 - val_loss: 2.6076 - val_accuracy: 0.5345 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 47/90\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 1.6132 - accuracy: 0.6905 - top_k_categorical_accuracy: 0.9762 - val_loss: 2.5739 - val_accuracy: 0.5345 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 48/90\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 1.5702 - accuracy: 0.7024 - top_k_categorical_accuracy: 0.9762 - val_loss: 2.5234 - val_accuracy: 0.5431 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 49/90\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 1.5142 - accuracy: 0.6905 - top_k_categorical_accuracy: 0.9762 - val_loss: 2.4630 - val_accuracy: 0.5517 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 50/90\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 1.4509 - accuracy: 0.6786 - top_k_categorical_accuracy: 0.9762 - val_loss: 2.4025 - val_accuracy: 0.6810 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 51/90\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 1.3878 - accuracy: 0.7381 - top_k_categorical_accuracy: 0.9762 - val_loss: 2.3506 - val_accuracy: 0.6897 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 52/90\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 1.3326 - accuracy: 0.7500 - top_k_categorical_accuracy: 0.9762 - val_loss: 2.3122 - val_accuracy: 0.6897 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 53/90\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 1.2911 - accuracy: 0.7500 - top_k_categorical_accuracy: 0.9762 - val_loss: 2.2891 - val_accuracy: 0.7069 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 54/90\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 1.2652 - accuracy: 0.7500 - top_k_categorical_accuracy: 0.9762 - val_loss: 2.2783 - val_accuracy: 0.7069 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 55/90\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 1.2529 - accuracy: 0.7500 - top_k_categorical_accuracy: 0.9762 - val_loss: 2.2735 - val_accuracy: 0.7328 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 56/90\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 1.2473 - accuracy: 0.8333 - top_k_categorical_accuracy: 0.9762 - val_loss: 2.2680 - val_accuracy: 0.7328 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 57/90\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 1.2412 - accuracy: 0.8333 - top_k_categorical_accuracy: 0.9762 - val_loss: 2.2573 - val_accuracy: 0.7328 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 58/90\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 1.2293 - accuracy: 0.8214 - top_k_categorical_accuracy: 0.9762 - val_loss: 2.2403 - val_accuracy: 0.7328 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 59/90\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 1.2099 - accuracy: 0.8214 - top_k_categorical_accuracy: 0.9762 - val_loss: 2.2186 - val_accuracy: 0.7328 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 60/90\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 1.1849 - accuracy: 0.8333 - top_k_categorical_accuracy: 0.9762 - val_loss: 2.1959 - val_accuracy: 0.7155 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 61/90\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 1.1582 - accuracy: 0.8571 - top_k_categorical_accuracy: 0.9762 - val_loss: 2.1758 - val_accuracy: 0.7155 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 62/90\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 1.1333 - accuracy: 0.8571 - top_k_categorical_accuracy: 0.9762 - val_loss: 2.1605 - val_accuracy: 0.7069 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 63/90\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 1.1128 - accuracy: 0.8452 - top_k_categorical_accuracy: 0.9762 - val_loss: 2.1501 - val_accuracy: 0.5776 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 64/90\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 1.0971 - accuracy: 0.7976 - top_k_categorical_accuracy: 0.9762 - val_loss: 2.1430 - val_accuracy: 0.5603 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 65/90\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 1.0854 - accuracy: 0.7857 - top_k_categorical_accuracy: 0.9762 - val_loss: 2.1363 - val_accuracy: 0.5603 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 66/90\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 1.0756 - accuracy: 0.7381 - top_k_categorical_accuracy: 0.9762 - val_loss: 2.1271 - val_accuracy: 0.5517 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 67/90\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 1.0655 - accuracy: 0.7262 - top_k_categorical_accuracy: 0.9762 - val_loss: 2.1136 - val_accuracy: 0.5517 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 68/90\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 1.0537 - accuracy: 0.7262 - top_k_categorical_accuracy: 0.9762 - val_loss: 2.0950 - val_accuracy: 0.5517 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 69/90\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 1.0397 - accuracy: 0.7262 - top_k_categorical_accuracy: 0.9762 - val_loss: 2.0721 - val_accuracy: 0.5517 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 70/90\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 1.0236 - accuracy: 0.7381 - top_k_categorical_accuracy: 0.9762 - val_loss: 2.0467 - val_accuracy: 0.5603 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 71/90\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 1.0063 - accuracy: 0.7619 - top_k_categorical_accuracy: 0.9762 - val_loss: 2.0207 - val_accuracy: 0.5948 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 72/90\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.9890 - accuracy: 0.7738 - top_k_categorical_accuracy: 0.9762 - val_loss: 1.9959 - val_accuracy: 0.6552 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 73/90\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.9727 - accuracy: 0.8452 - top_k_categorical_accuracy: 0.9762 - val_loss: 1.9738 - val_accuracy: 0.7069 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 74/90\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.9582 - accuracy: 0.8571 - top_k_categorical_accuracy: 0.9762 - val_loss: 1.9546 - val_accuracy: 0.7241 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 75/90\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.9454 - accuracy: 0.8571 - top_k_categorical_accuracy: 0.9762 - val_loss: 1.9380 - val_accuracy: 0.7155 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 76/90\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.9343 - accuracy: 0.8571 - top_k_categorical_accuracy: 0.9762 - val_loss: 1.9233 - val_accuracy: 0.7155 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 77/90\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.9241 - accuracy: 0.8571 - top_k_categorical_accuracy: 0.9762 - val_loss: 1.9096 - val_accuracy: 0.7155 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 78/90\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.9142 - accuracy: 0.8571 - top_k_categorical_accuracy: 0.9762 - val_loss: 1.8964 - val_accuracy: 0.7155 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 79/90\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.9042 - accuracy: 0.8571 - top_k_categorical_accuracy: 0.9762 - val_loss: 1.8833 - val_accuracy: 0.7155 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 80/90\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.8941 - accuracy: 0.8571 - top_k_categorical_accuracy: 0.9762 - val_loss: 1.8701 - val_accuracy: 0.7155 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 81/90\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.8837 - accuracy: 0.8571 - top_k_categorical_accuracy: 0.9762 - val_loss: 1.8570 - val_accuracy: 0.7155 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 82/90\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.8734 - accuracy: 0.8571 - top_k_categorical_accuracy: 0.9762 - val_loss: 1.8444 - val_accuracy: 0.7155 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 83/90\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.8632 - accuracy: 0.8571 - top_k_categorical_accuracy: 0.9762 - val_loss: 1.8323 - val_accuracy: 0.7155 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 84/90\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.8535 - accuracy: 0.8571 - top_k_categorical_accuracy: 0.9762 - val_loss: 1.8209 - val_accuracy: 0.7155 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 85/90\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.8443 - accuracy: 0.8571 - top_k_categorical_accuracy: 0.9762 - val_loss: 1.8103 - val_accuracy: 0.7155 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 86/90\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.8358 - accuracy: 0.8571 - top_k_categorical_accuracy: 0.9762 - val_loss: 1.8004 - val_accuracy: 0.7155 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 87/90\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.8279 - accuracy: 0.8571 - top_k_categorical_accuracy: 0.9762 - val_loss: 1.7912 - val_accuracy: 0.7155 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 88/90\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.8204 - accuracy: 0.8571 - top_k_categorical_accuracy: 0.9762 - val_loss: 1.7824 - val_accuracy: 0.7155 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 89/90\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.8132 - accuracy: 0.8571 - top_k_categorical_accuracy: 0.9762 - val_loss: 1.7740 - val_accuracy: 0.7155 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n",
      "Epoch 90/90\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.8061 - accuracy: 0.8571 - top_k_categorical_accuracy: 0.9762 - val_loss: 1.7657 - val_accuracy: 0.7155 - val_top_k_categorical_accuracy: 0.8966 - lr: 1.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f90501869a0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training_images = training_images[:1000]\n",
    "# training_labels = training_labels[:1000]\n",
    "# test_images = test_images[:100]\n",
    "# test_labels = test_labels[:100]\n",
    "\n",
    "training_images = tf.image.resize(training_images, [224, 224]).numpy()\n",
    "test_images = tf.image.resize(test_images, [224, 224]).numpy()\n",
    "\n",
    "# print('training_images before lamda: {}/{}'.format(training_images.shape, training_images.ndim))\n",
    "\n",
    "# training_images = tf.map_fn(lambda i: tf.stack([i]*3, axis=-1), training_images).numpy()\n",
    "# test_images = tf.map_fn(lambda i: tf.stack([i]*3, axis=-1), test_images).numpy()\n",
    "\n",
    "# print('training_images after lamda: {}/{}'.format(training_images.shape, training_images.ndim))\n",
    "\n",
    "training_images = tf.image.resize(training_images, [224, 224]).numpy()\n",
    "test_images = tf.image.resize(test_images, [224, 224]).numpy()\n",
    "\n",
    "# print('training_images shape: {}'.format(training_images.shape))\n",
    "# print('training_labels shape: {}'.format(training_labels.shape))\n",
    "# print('test_images shape: {}'.format(test_images.shape))\n",
    "# print('test_labels shape: {}'.format(test_labels.shape))\n",
    "\n",
    "training_images = training_images.reshape(200, 224, 224, 3)\n",
    "training_images = training_images / 255.0\n",
    "test_images = test_images.reshape(84, 224, 224, 3)\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "training_labels = tf.keras.utils.to_categorical(training_labels, num_classes=10)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=10)\n",
    "\n",
    "# num_len_train = int(0.8 * len(training_images))\n",
    "num_len_train = 84\n",
    "\n",
    "ttraining_images = training_images[:num_len_train]\n",
    "ttraining_labels = training_labels[:num_len_train]\n",
    "\n",
    "valid_images = training_images[num_len_train:]\n",
    "valid_labels = training_labels[num_len_train:]\n",
    "\n",
    "training_images = ttraining_images\n",
    "training_labels = ttraining_labels\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "                                    \n",
    "\t\ttf.keras.layers.Conv2D(96, (7, 7), strides=(2, 2), activation='relu',\n",
    "\t\t\tinput_shape=(224, 224, 3)),\n",
    "\t\ttf.keras.layers.MaxPooling2D(3, strides=2),\n",
    "    tf.keras.layers.Lambda(lambda x: tf.image.per_image_standardization(x)),\n",
    "\n",
    "\t\ttf.keras.layers.Conv2D(256, (5, 5), strides=(2, 2), activation='relu'),\n",
    "\t\ttf.keras.layers.MaxPooling2D(3, strides=2),\n",
    "    tf.keras.layers.Lambda(lambda x: tf.image.per_image_standardization(x)),\n",
    "\n",
    "\t\ttf.keras.layers.Conv2D(384, (3, 3), activation='relu'),\n",
    "\n",
    "\t\ttf.keras.layers.Conv2D(384, (3, 3), activation='relu'),\n",
    "\n",
    "\t\ttf.keras.layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "\n",
    "\t\ttf.keras.layers.MaxPooling2D(3, strides=2),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "\n",
    "\t\ttf.keras.layers.Dense(4096),\n",
    "\n",
    "\t\ttf.keras.layers.Dense(4096),\n",
    "\n",
    "\t\ttf.keras.layers.Dense(10, activation='softmax')\n",
    "\t])\n",
    "\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.01, momentum=0.9), \\\n",
    "              loss='categorical_crossentropy', \\\n",
    "              metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(5)])\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', \\\n",
    "                                            \t\tfactor=0.1, patience=1, \\\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tmin_lr=0.00001)\n",
    "# print('training_images length: {}'.format(len(training_images)))\n",
    "# print('training_labels length: {}'.format(len(training_labels)))\n",
    "\n",
    "model.fit(training_images, training_labels, batch_size=128, \\\n",
    "          validation_data=(valid_images, valid_labels), \\\n",
    "\t\t\t\t\tepochs=90, callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d43d1c-41ee-45f0-a341-3d2757eb5a12",
   "metadata": {},
   "source": [
    "## Evaluate the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7c21960-4a3d-46cb-8dfd-d3b8a8314ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 86ms/step - loss: 9.3497 - accuracy: 0.0476 - top_k_categorical_accuracy: 0.1190   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[9.34968090057373, 0.0476190485060215, 0.1190476194024086]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print('test_images length: {}'.format(len(test_images)))\n",
    "# print('test_labels length: {}'.format(len(test_labels)))\n",
    "\n",
    "model.evaluate(test_images,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18b52e25-9d06-4e81-b6c7-d317e158b35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = (model.predict(test_images) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37a2dd7f-3232-4b86-84e0-4e4b7137660b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.00      0.00      0.00        74\n",
      "           2       0.12      0.50      0.20         8\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.05      0.05      0.05        84\n",
      "   macro avg       0.01      0.05      0.02        84\n",
      "weighted avg       0.01      0.05      0.02        84\n",
      " samples avg       0.05      0.05      0.05        84\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luke/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/luke/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/luke/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006c0524-22ef-4ad4-8403-faec5dc9f5f4",
   "metadata": {},
   "source": [
    "## Free up the GPU's memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b4c59ac-35fd-420c-ab71-2dc2c7c457ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda.select_device(0)\n",
    "cuda.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e26dd5-f8f1-40be-81d5-d9be1b3f8467",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
