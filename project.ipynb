{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ad62cb3-b86d-4a0a-8492-ef09608a4c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fix last dense layer. Is it the number of classes? If so then nothing to fix\n",
    "# TODO: discuss how reading in dataset could be made multi-threaded (each dataset is read in on own thread then all joined together at the end)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import imageio as iio\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from numba import cuda  # https://stackoverflow.com/a/52354865/6476994\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "import re\n",
    "from datetime import datetime\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c4a177c-422b-48b4-b51f-ac05542a4e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# allows all images to be displayed at once (else only displays the last call to plt.imshow())\n",
    "# https://stackoverflow.com/a/41210974\n",
    "def displayImage(image, caption = None, colour = None) -> None:\n",
    "    plt.figure()\n",
    "    if(colour != None):\n",
    "        plt.imshow(image, cmap=colour)\n",
    "    else:\n",
    "        plt.imshow(image)\n",
    "        \n",
    "    if(caption != None):\n",
    "        # display caption below picture (https://stackoverflow.com/a/51486361)\n",
    "        plt.figtext(0.5, 0.01, caption, wrap=True, horizontalalignment='center', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7119a4c7-53e6-47b3-a57c-c8c54758002a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_names: ['BB01', 'BB02', 'BB03', 'BB04', 'BB05', 'BB06', 'BB07', 'BB08', 'BB09', 'BB10', 'BB11', 'BB12', 'BB13', 'BB14', 'BB15', 'BB16', 'BB17', 'BB18', 'BB19', 'BB20', 'BB21', 'BB22', 'BB23', 'BB24', 'BB25', 'BB26', 'BB27', 'BB28', 'BB29', 'BB30']\n"
     ]
    }
   ],
   "source": [
    "# dataset_names = [\"BB01\", \"BB02\", \"BB03\", \"BB04\", \"BB05\"]\n",
    "dataset_names = [\"BB01\", \"BB02\", \"BB03\", \"BB04\", \"BB05\", \"BB06\", \"BB07\", \"BB08\", \"BB09\", \"BB10\"]\n",
    "for i in range(11, 31):\n",
    "    dataset_names.append(\"BB{}\".format(i))\n",
    "print(\"dataset_names: {}\".format(dataset_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2162b806-d6bd-47ba-acc3-3f7209a27997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# free up GPU if it didn't after the last run\n",
    "cuda.select_device(0)\n",
    "cuda.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760dbfe7-ea61-44ed-bbbd-1d3d3b576c3f",
   "metadata": {},
   "source": [
    "# Read in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfbb46df-237c-4f68-b1af-5ee75f6b69b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading in images for dataset: BB01\n",
      "all_image_filenames length: 285\n",
      "done current dataset\n",
      "reading in images for dataset: BB02\n",
      "all_image_filenames length: 45\n",
      "done current dataset\n",
      "reading in images for dataset: BB03\n",
      "all_image_filenames length: 230\n",
      "done current dataset\n",
      "reading in images for dataset: BB04\n",
      "all_image_filenames length: 999\n",
      "done current dataset\n",
      "reading in images for dataset: BB05\n",
      "all_image_filenames length: 189\n",
      "done current dataset\n",
      "reading in images for dataset: BB06\n",
      "all_image_filenames length: 1137\n",
      "done current dataset\n",
      "reading in images for dataset: BB07\n",
      "all_image_filenames length: 324\n",
      "done current dataset\n",
      "reading in images for dataset: BB08\n",
      "all_image_filenames length: 66\n",
      "done current dataset\n",
      "reading in images for dataset: BB09\n",
      "all_image_filenames length: 357\n",
      "done current dataset\n",
      "reading in images for dataset: BB10\n",
      "all_image_filenames length: 121\n",
      "done current dataset\n",
      "reading in images for dataset: BB11\n",
      "all_image_filenames length: 167\n",
      "done current dataset\n",
      "reading in images for dataset: BB12\n",
      "all_image_filenames length: 157\n",
      "done current dataset\n",
      "reading in images for dataset: BB13\n",
      "all_image_filenames length: 50\n",
      "done current dataset\n",
      "reading in images for dataset: BB14\n",
      "all_image_filenames length: 367\n",
      "done current dataset\n",
      "reading in images for dataset: BB15\n",
      "all_image_filenames length: 91\n",
      "done current dataset\n",
      "reading in images for dataset: BB16\n",
      "all_image_filenames length: 213\n",
      "done current dataset\n",
      "reading in images for dataset: BB17\n",
      "all_image_filenames length: 26\n",
      "done current dataset\n",
      "reading in images for dataset: BB18\n",
      "all_image_filenames length: 75\n",
      "done current dataset\n",
      "reading in images for dataset: BB19\n",
      "all_image_filenames length: 72\n",
      "done current dataset\n",
      "reading in images for dataset: BB20\n",
      "all_image_filenames length: 96\n",
      "done current dataset\n",
      "reading in images for dataset: BB21\n",
      "all_image_filenames length: 78\n",
      "done current dataset\n",
      "reading in images for dataset: BB22\n",
      "all_image_filenames length: 123\n",
      "done current dataset\n",
      "reading in images for dataset: BB23\n",
      "all_image_filenames length: 192\n",
      "done current dataset\n",
      "reading in images for dataset: BB24\n",
      "all_image_filenames length: 62\n",
      "done current dataset\n",
      "reading in images for dataset: BB25\n",
      "all_image_filenames length: 10\n",
      "done current dataset\n",
      "reading in images for dataset: BB26\n",
      "all_image_filenames length: 142\n",
      "done current dataset\n",
      "reading in images for dataset: BB27\n",
      "all_image_filenames length: 46\n",
      "done current dataset\n",
      "reading in images for dataset: BB28\n",
      "all_image_filenames length: 73\n",
      "done current dataset\n",
      "reading in images for dataset: BB29\n",
      "all_image_filenames length: 20\n",
      "done current dataset\n",
      "reading in images for dataset: BB30\n",
      "all_image_filenames length: 450\n",
      "done current dataset\n"
     ]
    }
   ],
   "source": [
    "# get the all original output filenames\n",
    "def readInImages(datasetName):\n",
    "    print(\"reading in images for dataset: {}\".format(datasetName))\n",
    "    desired_size = 224\n",
    "    image_list = []\n",
    "    imgRegExp = re.compile(r'.*[.](JPG)$')\n",
    "    # https://stackoverflow.com/a/3207973\n",
    "    all_image_filenames = next(os.walk('data/{}'.format(datasetName)),\n",
    "                         (None, None, []))[2]  # [] if no file\n",
    "    # filter out file names that are not JPEGs\n",
    "    all_image_filenames = [i for i in all_image_filenames if imgRegExp.match(i)]\n",
    "    # walk() outputs unordered, so we need to sort\n",
    "    all_image_filenames.sort()\n",
    "    # print(\"all_image_filenames: {}\".format(all_image_filenames))\n",
    "    print(\"all_image_filenames length: {}\".format(len(all_image_filenames)))\n",
    "    for fn in all_image_filenames:\n",
    "        # im = Image.open('data/{}/{}'.format(datasetName, fn))\n",
    "        im = cv2.imread('data/{}/{}'.format(datasetName, fn))\n",
    "        # resize the image to conserve memory, and transform it to be square while\n",
    "        # maintaining the aspect ration (give it padding):\n",
    "        # https://jdhao.github.io/2017/11/06/resize-image-to-square-with-padding/#using-opencv\n",
    "        # im = cv2.resize(im, (480, 270), interpolation=cv2.INTER_CUBIC)\n",
    "        # im = cv2.resize(im, (240, 135), interpolation=cv2.INTER_CUBIC)\n",
    "        # im = cv2.resize(im, (192, 108), interpolation=cv2.INTER_CUBIC)\n",
    "        old_size = im.shape[:2]\n",
    "        ratio = float(desired_size)/max(old_size)\n",
    "        new_size = tuple([int(x*ratio) for x in old_size])\n",
    "        im = cv2.resize(im, (new_size[1], new_size[0]))\n",
    "\n",
    "        delta_w = desired_size - new_size[1]\n",
    "        delta_h = desired_size - new_size[0]\n",
    "        top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "        left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "\n",
    "        color = [0, 0, 0]\n",
    "        new_im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)\n",
    "\n",
    "        \n",
    "        image_list.append(np.asarray(new_im))\n",
    "    \n",
    "    print(\"done current dataset\")\n",
    "    return image_list\n",
    "\n",
    "all_images = []\n",
    "for fn in dataset_names:    \n",
    "    all_images = [*all_images, *readInImages(fn)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aded9195-def1-48e6-bb54-4062ec01dc5b",
   "metadata": {},
   "source": [
    "# Read in dataset's labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d14a993b-efcc-4927-b522-44cbb90e8295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all classes (length=8): {'Other', 'Emu', 'Kangaroo', 'Rabbit', 'Human Presense/Deployment', 'Cat', 'Empty photo', 'Fox'}\n"
     ]
    }
   ],
   "source": [
    "# labels (using dataset's CSV file)\n",
    "\n",
    "def readInAnnotations(datasetName):\n",
    "    labelList = []\n",
    "    # https://realpython.com/python-csv/#reading-csv-files-with-csv\n",
    "    with open('data/{}/{}.csv'.format(datasetName, datasetName)) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        line_count = 0\n",
    "        for row in csv_reader:\n",
    "            # print(\"row: {}\".format(row))\n",
    "            # first row always contains this string, so ignore it\n",
    "            if \"RECONYX - MapView Professional\" in row:\n",
    "                continue\n",
    "            if line_count == 0:\n",
    "                # print(f'Column names are {\", \".join(row)}')\n",
    "                line_count += 1\n",
    "            else:\n",
    "                # print(\"Image Name: {}. Hit List: {}\".format(row[0], row[22].replace(\"\\n\", \", \")))\n",
    "                # FIXME handle when hitlist contains more than one item (e.g., BB06 IMG_512 has 'kangaroo' and 'empty photo') - sort of handled, need to make more dynamic\n",
    "                hit_list = row[22]\n",
    "                if hit_list == '':\n",
    "                    labelList.append(\"Empty photo\")\n",
    "                elif hit_list == 'Empty photo\\nHuman Presense/Deployment':\n",
    "                    labelList.append(\"Human Presense/Deployment\")\n",
    "                elif hit_list == 'Kangaroo\\nEmpty photo':\n",
    "                    labelList.append(\"Kangaroo\")\n",
    "                else:\n",
    "                    # FIXME: rendundant case?\n",
    "                    labelList.append(hit_list.replace(\"\\n\", \", \"))\n",
    "                line_count += 1\n",
    "    # print(\"returning labelList (length: {}): {}\".format(len(labelList), labelList))\n",
    "    # print(\"returning labelList of length: {}\".format(len(labelList)))\n",
    "    return labelList\n",
    "\n",
    "all_image_labels = []\n",
    "for fn in dataset_names:\n",
    "    all_image_labels = [*all_image_labels, *readInAnnotations(fn)]\n",
    "\n",
    "# print(\"all_image_labels: {}\".format(all_image_labels))\n",
    "\n",
    "classes = set(all_image_labels)\n",
    "print(\"all classes (length={}): {}\".format(len(classes), classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f21c8c-b002-41c6-8ee5-8c249bc7f2aa",
   "metadata": {},
   "source": [
    "# Randomly split the dataset and corresponding labels into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44e9f9bb-0adf-4b24-8bb7-6607dccd3ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_images size: 6263\n",
      "training_labels length: 5010\n",
      "test_labels length: 1253\n",
      "test_labels: ['Kangaroo', 'Kangaroo', 'Human Presense/Deployment', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Human Presense/Deployment', 'Kangaroo', 'Emu', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Emu', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Human Presense/Deployment', 'Emu', 'Human Presense/Deployment', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Empty photo', 'Emu', 'Kangaroo', 'Empty photo', 'Human Presense/Deployment', 'Empty photo', 'Kangaroo', 'Emu', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Empty photo', 'Kangaroo', 'Empty photo', 'Emu', 'Human Presense/Deployment', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Emu', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Human Presense/Deployment', 'Kangaroo', 'Emu', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Emu', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Fox', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Emu', 'Emu', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Human Presense/Deployment', 'Kangaroo', 'Kangaroo', 'Emu', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Emu', 'Kangaroo', 'Kangaroo', 'Human Presense/Deployment', 'Empty photo', 'Kangaroo', 'Empty photo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Emu', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Fox', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Emu', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Emu', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Emu', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Emu', 'Emu', 'Human Presense/Deployment', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Empty photo', 'Fox', 'Kangaroo', 'Emu', 'Kangaroo', 'Rabbit', 'Other', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Emu', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Human Presense/Deployment', 'Kangaroo', 'Kangaroo', 'Emu', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Emu', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Human Presense/Deployment', 'Kangaroo', 'Empty photo', 'Empty photo', 'Kangaroo', 'Human Presense/Deployment', 'Emu', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Human Presense/Deployment', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Human Presense/Deployment', 'Emu', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Human Presense/Deployment', 'Human Presense/Deployment', 'Kangaroo', 'Emu', 'Human Presense/Deployment', 'Emu', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Empty photo', 'Human Presense/Deployment', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Emu', 'Kangaroo', 'Empty photo', 'Emu', 'Human Presense/Deployment', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Fox', 'Kangaroo', 'Empty photo', 'Fox', 'Kangaroo', 'Cat', 'Kangaroo', 'Emu', 'Kangaroo', 'Emu', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Human Presense/Deployment', 'Empty photo', 'Kangaroo', 'Human Presense/Deployment', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Empty photo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Emu', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Human Presense/Deployment', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Cat', 'Kangaroo', 'Emu', 'Human Presense/Deployment', 'Emu', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Emu', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Human Presense/Deployment', 'Kangaroo', 'Kangaroo', 'Human Presense/Deployment', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Fox', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Emu', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Human Presense/Deployment', 'Emu', 'Fox', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Human Presense/Deployment', 'Emu', 'Kangaroo', 'Human Presense/Deployment', 'Kangaroo', 'Kangaroo', 'Human Presense/Deployment', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Empty photo', 'Fox', 'Kangaroo', 'Emu', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Fox', 'Human Presense/Deployment', 'Human Presense/Deployment', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Fox', 'Empty photo', 'Cat', 'Empty photo', 'Kangaroo', 'Emu', 'Kangaroo', 'Other', 'Emu', 'Kangaroo', 'Human Presense/Deployment', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Emu', 'Kangaroo', 'Kangaroo', 'Human Presense/Deployment', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Human Presense/Deployment', 'Kangaroo', 'Kangaroo', 'Cat', 'Empty photo', 'Fox', 'Kangaroo', 'Kangaroo', 'Emu', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Emu', 'Human Presense/Deployment', 'Kangaroo', 'Human Presense/Deployment', 'Kangaroo', 'Kangaroo', 'Rabbit', 'Human Presense/Deployment', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Emu', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Empty photo', 'Kangaroo', 'Fox', 'Rabbit', 'Kangaroo', 'Kangaroo', 'Emu', 'Emu', 'Kangaroo', 'Kangaroo', 'Emu', 'Empty photo', 'Empty photo', 'Kangaroo', 'Emu', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Emu', 'Emu', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Emu', 'Human Presense/Deployment', 'Human Presense/Deployment', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Emu', 'Human Presense/Deployment', 'Human Presense/Deployment', 'Empty photo', 'Human Presense/Deployment', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Emu', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Emu', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Human Presense/Deployment', 'Cat', 'Kangaroo', 'Human Presense/Deployment', 'Kangaroo', 'Kangaroo', 'Human Presense/Deployment', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Human Presense/Deployment', 'Empty photo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Emu', 'Fox', 'Kangaroo', 'Kangaroo', 'Emu', 'Kangaroo', 'Human Presense/Deployment', 'Human Presense/Deployment', 'Empty photo', 'Emu', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Emu', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Human Presense/Deployment', 'Emu', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Emu', 'Human Presense/Deployment', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Human Presense/Deployment', 'Kangaroo', 'Human Presense/Deployment', 'Kangaroo', 'Emu', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Human Presense/Deployment', 'Kangaroo', 'Human Presense/Deployment', 'Emu', 'Empty photo', 'Emu', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Human Presense/Deployment', 'Empty photo', 'Human Presense/Deployment', 'Empty photo', 'Emu', 'Kangaroo', 'Emu', 'Other', 'Emu', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Emu', 'Kangaroo', 'Other', 'Empty photo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Human Presense/Deployment', 'Empty photo', 'Emu', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Cat', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Human Presense/Deployment', 'Human Presense/Deployment', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Empty photo', 'Kangaroo', 'Human Presense/Deployment', 'Emu', 'Human Presense/Deployment', 'Human Presense/Deployment', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Fox', 'Kangaroo', 'Kangaroo', 'Human Presense/Deployment', 'Emu', 'Human Presense/Deployment', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Fox', 'Empty photo', 'Emu', 'Empty photo', 'Human Presense/Deployment', 'Empty photo', 'Rabbit', 'Empty photo', 'Fox', 'Emu', 'Human Presense/Deployment', 'Emu', 'Human Presense/Deployment', 'Emu', 'Other', 'Kangaroo', 'Kangaroo', 'Human Presense/Deployment', 'Kangaroo', 'Human Presense/Deployment', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Emu', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Emu', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Other', 'Empty photo', 'Emu', 'Kangaroo', 'Emu', 'Kangaroo', 'Empty photo', 'Empty photo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Human Presense/Deployment', 'Empty photo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Fox', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Emu', 'Kangaroo', 'Human Presense/Deployment', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Fox', 'Emu', 'Kangaroo', 'Emu', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Empty photo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Emu', 'Other', 'Kangaroo', 'Emu', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Cat', 'Empty photo', 'Empty photo', 'Kangaroo', 'Emu', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Emu', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Emu', 'Empty photo', 'Fox', 'Human Presense/Deployment', 'Fox', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Emu', 'Kangaroo', 'Empty photo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Emu', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Emu', 'Kangaroo', 'Human Presense/Deployment', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Emu', 'Empty photo', 'Kangaroo', 'Emu', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Emu', 'Empty photo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Emu', 'Kangaroo', 'Other', 'Kangaroo', 'Emu', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Emu', 'Fox', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Fox', 'Empty photo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Empty photo', 'Emu', 'Fox', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Human Presense/Deployment', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Emu', 'Other', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Human Presense/Deployment', 'Kangaroo', 'Emu', 'Human Presense/Deployment', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Emu', 'Kangaroo', 'Human Presense/Deployment', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Emu', 'Kangaroo', 'Human Presense/Deployment', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Emu', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Empty photo', 'Empty photo', 'Empty photo', 'Kangaroo', 'Empty photo', 'Empty photo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Human Presense/Deployment', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Fox', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Fox', 'Kangaroo', 'Empty photo', 'Emu', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Emu', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Human Presense/Deployment', 'Empty photo', 'Human Presense/Deployment', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Human Presense/Deployment', 'Empty photo', 'Other', 'Human Presense/Deployment', 'Empty photo', 'Kangaroo', 'Emu', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Human Presense/Deployment', 'Emu', 'Empty photo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Emu', 'Kangaroo', 'Kangaroo', 'Human Presense/Deployment', 'Kangaroo', 'Emu', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Emu', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Human Presense/Deployment', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Human Presense/Deployment', 'Empty photo', 'Empty photo', 'Emu', 'Fox', 'Human Presense/Deployment', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Empty photo', 'Emu', 'Kangaroo', 'Kangaroo', 'Emu', 'Kangaroo', 'Emu', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Human Presense/Deployment', 'Emu', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Human Presense/Deployment', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Human Presense/Deployment', 'Kangaroo', 'Empty photo', 'Emu', 'Empty photo', 'Kangaroo', 'Human Presense/Deployment', 'Emu', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Human Presense/Deployment', 'Kangaroo', 'Empty photo', 'Emu', 'Emu', 'Kangaroo', 'Empty photo', 'Human Presense/Deployment', 'Kangaroo', 'Emu', 'Kangaroo', 'Emu', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Fox', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Emu', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Human Presense/Deployment', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Emu', 'Emu', 'Kangaroo', 'Emu', 'Kangaroo', 'Kangaroo', 'Human Presense/Deployment', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Human Presense/Deployment', 'Human Presense/Deployment', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Empty photo', 'Emu', 'Emu', 'Kangaroo', 'Human Presense/Deployment', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Empty photo', 'Empty photo', 'Emu', 'Kangaroo', 'Kangaroo', 'Fox', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Emu', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Emu', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Human Presense/Deployment', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Human Presense/Deployment', 'Kangaroo', 'Kangaroo', 'Other', 'Empty photo', 'Human Presense/Deployment', 'Kangaroo', 'Kangaroo', 'Emu', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Human Presense/Deployment', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Human Presense/Deployment', 'Kangaroo', 'Emu', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Emu', 'Emu', 'Empty photo', 'Kangaroo', 'Emu', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Empty photo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Kangaroo', 'Emu', 'Emu', 'Kangaroo', 'Empty photo', 'Kangaroo', 'Kangaroo', 'Empty photo']\n",
      "counter: Counter({'Kangaroo': 756, 'Empty photo': 206, 'Emu': 136, 'Human Presense/Deployment': 105, 'Fox': 28, 'Other': 11, 'Cat': 7, 'Rabbit': 4})\n",
      "training_classes (length=8): ['Kangaroo', 'Empty photo', 'Human Presense/Deployment', 'Emu', 'Fox', 'Cat', 'Other', 'Rabbit']\n",
      "test_classes (length=8): ['Kangaroo', 'Human Presense/Deployment', 'Empty photo', 'Emu', 'Fox', 'Rabbit', 'Other', 'Cat']\n",
      "done stacking\n",
      "training_images shape: (5010, 224, 224, 3)\n",
      "test_images shape: (1253, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"all_images size: {}\".format(len(all_images)))\n",
    "# print(\"all_image_labels size: {}\".format(len(all_image_labels)))\n",
    "\n",
    "\n",
    "training_images, test_images, training_labels, test_labels = train_test_split(all_images, all_image_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"training_labels length: {}\".format(len(training_labels)))\n",
    "print(\"test_labels length: {}\".format(len(test_labels)))\n",
    "# print(\"test_labels: {}\".format(test_labels))\n",
    "counter = collections.Counter(test_labels)\n",
    "print(\"counter: {}\".format(counter))\n",
    "\n",
    "# training_classes = set(training_labels)\n",
    "training_classes = []\n",
    "for label in training_labels:\n",
    "    if label not in training_classes:\n",
    "        training_classes.append(label)\n",
    "# test_classes = set(test_labels)\n",
    "test_classes = []\n",
    "for label in test_labels:\n",
    "    if label not in test_classes:\n",
    "        test_classes.append(label)\n",
    "print(\"training_classes (length={}): {}\".format(len(training_classes), training_classes))\n",
    "print(\"test_classes (length={}): {}\".format(len(test_classes), test_classes))\n",
    "\n",
    "# integer-encode labels so they can be one-hot-encoded\n",
    "# https://stackoverflow.com/a/56227965/6476994\n",
    "label_encoder = LabelEncoder()\n",
    "training_labels = np.array(training_labels)\n",
    "training_labels = label_encoder.fit_transform(training_labels)\n",
    "test_labels = np.array(test_labels)\n",
    "test_labels = label_encoder.fit_transform(test_labels)\n",
    "\n",
    "\n",
    "# convert list of numpy arrays to numpy array of numpy arrays\n",
    "# https://stackoverflow.com/a/27516930/6476994\n",
    "training_images = np.stack(training_images, axis = 0)\n",
    "test_images = np.stack(test_images, axis = 0)\n",
    "\n",
    "print(\"done stacking\")\n",
    "print(\"training_images shape: {}\".format(training_images.shape))\n",
    "print(\"test_images shape: {}\".format(test_images.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de40603-e6cd-4c93-856c-eed237c3f7dc",
   "metadata": {},
   "source": [
    "# ZFNet\n",
    "\n",
    "Source: https://towardsdatascience.com/zfnet-an-explanation-of-paper-with-code-f1bd6752121d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da469ee2-ad90-402b-9b57-55a1388138e3",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d882d77-9109-494a-8c37-7ee3518adf8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-29 08:04:40.052223: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-29 08:04:40.055256: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-29 08:04:40.055428: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-29 08:04:40.055811: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-29 08:04:40.056270: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-29 08:04:40.056421: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-29 08:04:40.056555: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-29 08:04:40.364913: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-29 08:04:40.365088: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-29 08:04:40.365232: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-29 08:04:40.365360: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5055 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070, pci bus id: 0000:2b:00.0, compute capability: 7.5\n",
      "2022-05-29 08:04:40.821108: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 3016581120 exceeds 10% of free system memory.\n",
      "/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "2022-05-29 08:04:43.288193: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2413264896 exceeds 10% of free system memory.\n",
      "2022-05-29 08:04:44.062926: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2413264896 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-29 08:04:45.574507: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2022-05-29 08:04:45.898114: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2022-05-29 08:04:47.634244: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 982.19MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-05-29 08:04:47.634276: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 982.19MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - ETA: 0s - loss: 1.4251 - accuracy: 0.5561 - top_k_categorical_accuracy: 0.9746"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-29 08:04:54.682329: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 722.21MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-05-29 08:04:54.682357: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 722.21MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 10s 230ms/step - loss: 1.4251 - accuracy: 0.5561 - top_k_categorical_accuracy: 0.9746 - val_loss: 1.1133 - val_accuracy: 0.6128 - val_top_k_categorical_accuracy: 0.9890 - lr: 0.0100\n",
      "Epoch 2/90\n",
      "32/32 [==============================] - 6s 178ms/step - loss: 1.0436 - accuracy: 0.6255 - top_k_categorical_accuracy: 0.9895 - val_loss: 1.0536 - val_accuracy: 0.6118 - val_top_k_categorical_accuracy: 0.9880 - lr: 0.0100\n",
      "Epoch 3/90\n",
      "32/32 [==============================] - 6s 179ms/step - loss: 0.9468 - accuracy: 0.6477 - top_k_categorical_accuracy: 0.9925 - val_loss: 0.9259 - val_accuracy: 0.6866 - val_top_k_categorical_accuracy: 0.9910 - lr: 0.0100\n",
      "Epoch 4/90\n",
      "32/32 [==============================] - 6s 179ms/step - loss: 0.8940 - accuracy: 0.6619 - top_k_categorical_accuracy: 0.9935 - val_loss: 0.8750 - val_accuracy: 0.6846 - val_top_k_categorical_accuracy: 0.9940 - lr: 0.0100\n",
      "Epoch 5/90\n",
      "32/32 [==============================] - 6s 181ms/step - loss: 0.8514 - accuracy: 0.6839 - top_k_categorical_accuracy: 0.9920 - val_loss: 0.8807 - val_accuracy: 0.7016 - val_top_k_categorical_accuracy: 0.9960 - lr: 0.0100\n",
      "Epoch 6/90\n",
      "32/32 [==============================] - 6s 179ms/step - loss: 0.8936 - accuracy: 0.6954 - top_k_categorical_accuracy: 0.9880 - val_loss: 0.8113 - val_accuracy: 0.7196 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-03\n",
      "Epoch 7/90\n",
      "32/32 [==============================] - 6s 180ms/step - loss: 0.7259 - accuracy: 0.7350 - top_k_categorical_accuracy: 0.9950 - val_loss: 0.7537 - val_accuracy: 0.7405 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-03\n",
      "Epoch 8/90\n",
      "32/32 [==============================] - 6s 179ms/step - loss: 0.6830 - accuracy: 0.7520 - top_k_categorical_accuracy: 0.9955 - val_loss: 0.7372 - val_accuracy: 0.7555 - val_top_k_categorical_accuracy: 0.9950 - lr: 1.0000e-03\n",
      "Epoch 9/90\n",
      "32/32 [==============================] - 6s 179ms/step - loss: 0.6608 - accuracy: 0.7645 - top_k_categorical_accuracy: 0.9958 - val_loss: 0.7189 - val_accuracy: 0.7635 - val_top_k_categorical_accuracy: 0.9950 - lr: 1.0000e-03\n",
      "Epoch 10/90\n",
      "32/32 [==============================] - 6s 180ms/step - loss: 0.6401 - accuracy: 0.7727 - top_k_categorical_accuracy: 0.9963 - val_loss: 0.7138 - val_accuracy: 0.7585 - val_top_k_categorical_accuracy: 0.9950 - lr: 1.0000e-03\n",
      "Epoch 11/90\n",
      "32/32 [==============================] - 6s 179ms/step - loss: 0.6189 - accuracy: 0.7789 - top_k_categorical_accuracy: 0.9963 - val_loss: 0.6766 - val_accuracy: 0.7675 - val_top_k_categorical_accuracy: 0.9950 - lr: 1.0000e-03\n",
      "Epoch 12/90\n",
      "32/32 [==============================] - 6s 180ms/step - loss: 0.6046 - accuracy: 0.7872 - top_k_categorical_accuracy: 0.9965 - val_loss: 0.6681 - val_accuracy: 0.7784 - val_top_k_categorical_accuracy: 0.9940 - lr: 1.0000e-03\n",
      "Epoch 13/90\n",
      "32/32 [==============================] - 6s 181ms/step - loss: 0.5959 - accuracy: 0.7964 - top_k_categorical_accuracy: 0.9968 - val_loss: 0.6493 - val_accuracy: 0.7864 - val_top_k_categorical_accuracy: 0.9940 - lr: 1.0000e-03\n",
      "Epoch 14/90\n",
      "32/32 [==============================] - 6s 180ms/step - loss: 0.5731 - accuracy: 0.7994 - top_k_categorical_accuracy: 0.9960 - val_loss: 0.6348 - val_accuracy: 0.7864 - val_top_k_categorical_accuracy: 0.9950 - lr: 1.0000e-03\n",
      "Epoch 15/90\n",
      "32/32 [==============================] - 6s 188ms/step - loss: 0.5606 - accuracy: 0.8064 - top_k_categorical_accuracy: 0.9973 - val_loss: 0.6345 - val_accuracy: 0.7904 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-03\n",
      "Epoch 16/90\n",
      "32/32 [==============================] - 6s 181ms/step - loss: 0.5553 - accuracy: 0.8049 - top_k_categorical_accuracy: 0.9963 - val_loss: 0.6243 - val_accuracy: 0.8044 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-03\n",
      "Epoch 17/90\n",
      "32/32 [==============================] - 6s 183ms/step - loss: 0.5390 - accuracy: 0.8154 - top_k_categorical_accuracy: 0.9975 - val_loss: 0.6133 - val_accuracy: 0.8004 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-03\n",
      "Epoch 18/90\n",
      "32/32 [==============================] - 6s 185ms/step - loss: 0.5218 - accuracy: 0.8229 - top_k_categorical_accuracy: 0.9975 - val_loss: 0.6098 - val_accuracy: 0.7994 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-03\n",
      "Epoch 19/90\n",
      "32/32 [==============================] - 6s 181ms/step - loss: 0.5047 - accuracy: 0.8273 - top_k_categorical_accuracy: 0.9978 - val_loss: 0.5867 - val_accuracy: 0.8044 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-03\n",
      "Epoch 20/90\n",
      "32/32 [==============================] - 6s 181ms/step - loss: 0.4888 - accuracy: 0.8331 - top_k_categorical_accuracy: 0.9978 - val_loss: 0.5736 - val_accuracy: 0.8124 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-03\n",
      "Epoch 21/90\n",
      "32/32 [==============================] - 6s 181ms/step - loss: 0.4830 - accuracy: 0.8368 - top_k_categorical_accuracy: 0.9975 - val_loss: 0.6159 - val_accuracy: 0.8014 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-03\n",
      "Epoch 22/90\n",
      "32/32 [==============================] - 6s 182ms/step - loss: 0.5167 - accuracy: 0.8179 - top_k_categorical_accuracy: 0.9975 - val_loss: 0.5679 - val_accuracy: 0.8154 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-04\n",
      "Epoch 23/90\n",
      "32/32 [==============================] - 6s 182ms/step - loss: 0.4600 - accuracy: 0.8406 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5541 - val_accuracy: 0.8214 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-04\n",
      "Epoch 24/90\n",
      "32/32 [==============================] - 6s 181ms/step - loss: 0.4500 - accuracy: 0.8463 - top_k_categorical_accuracy: 0.9978 - val_loss: 0.5520 - val_accuracy: 0.8214 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-04\n",
      "Epoch 25/90\n",
      "32/32 [==============================] - 6s 182ms/step - loss: 0.4450 - accuracy: 0.8473 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5495 - val_accuracy: 0.8194 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-04\n",
      "Epoch 26/90\n",
      "32/32 [==============================] - 6s 182ms/step - loss: 0.4424 - accuracy: 0.8496 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5489 - val_accuracy: 0.8184 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-04\n",
      "Epoch 27/90\n",
      "32/32 [==============================] - 6s 181ms/step - loss: 0.4409 - accuracy: 0.8505 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5487 - val_accuracy: 0.8194 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-04\n",
      "Epoch 28/90\n",
      "32/32 [==============================] - 6s 182ms/step - loss: 0.4386 - accuracy: 0.8518 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5468 - val_accuracy: 0.8204 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-04\n",
      "Epoch 29/90\n",
      "32/32 [==============================] - 6s 182ms/step - loss: 0.4363 - accuracy: 0.8520 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5488 - val_accuracy: 0.8224 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-04\n",
      "Epoch 30/90\n",
      "32/32 [==============================] - 6s 182ms/step - loss: 0.4338 - accuracy: 0.8528 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5463 - val_accuracy: 0.8224 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 31/90\n",
      "32/32 [==============================] - 6s 181ms/step - loss: 0.4327 - accuracy: 0.8533 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5452 - val_accuracy: 0.8204 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 32/90\n",
      "32/32 [==============================] - 6s 182ms/step - loss: 0.4321 - accuracy: 0.8525 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5448 - val_accuracy: 0.8204 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 33/90\n",
      "32/32 [==============================] - 6s 182ms/step - loss: 0.4320 - accuracy: 0.8545 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5449 - val_accuracy: 0.8204 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 34/90\n",
      "32/32 [==============================] - 6s 182ms/step - loss: 0.4317 - accuracy: 0.8530 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5449 - val_accuracy: 0.8194 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 35/90\n",
      "32/32 [==============================] - 6s 182ms/step - loss: 0.4315 - accuracy: 0.8540 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5448 - val_accuracy: 0.8204 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 36/90\n",
      "32/32 [==============================] - 6s 183ms/step - loss: 0.4313 - accuracy: 0.8540 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5444 - val_accuracy: 0.8194 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 37/90\n",
      "32/32 [==============================] - 6s 182ms/step - loss: 0.4311 - accuracy: 0.8530 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5447 - val_accuracy: 0.8194 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 38/90\n",
      "32/32 [==============================] - 6s 186ms/step - loss: 0.4309 - accuracy: 0.8545 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5445 - val_accuracy: 0.8214 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 39/90\n",
      "32/32 [==============================] - 6s 182ms/step - loss: 0.4308 - accuracy: 0.8528 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5445 - val_accuracy: 0.8194 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 40/90\n",
      "32/32 [==============================] - 6s 181ms/step - loss: 0.4306 - accuracy: 0.8540 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5443 - val_accuracy: 0.8224 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 41/90\n",
      "32/32 [==============================] - 6s 181ms/step - loss: 0.4305 - accuracy: 0.8535 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5440 - val_accuracy: 0.8204 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 42/90\n",
      "32/32 [==============================] - 6s 184ms/step - loss: 0.4302 - accuracy: 0.8538 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5440 - val_accuracy: 0.8214 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 43/90\n",
      "32/32 [==============================] - 6s 185ms/step - loss: 0.4301 - accuracy: 0.8538 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5439 - val_accuracy: 0.8214 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 44/90\n",
      "32/32 [==============================] - 6s 180ms/step - loss: 0.4301 - accuracy: 0.8543 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5436 - val_accuracy: 0.8204 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 45/90\n",
      "32/32 [==============================] - 6s 183ms/step - loss: 0.4298 - accuracy: 0.8553 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5434 - val_accuracy: 0.8194 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 46/90\n",
      "32/32 [==============================] - 6s 182ms/step - loss: 0.4296 - accuracy: 0.8545 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5433 - val_accuracy: 0.8204 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 47/90\n",
      "32/32 [==============================] - 6s 182ms/step - loss: 0.4294 - accuracy: 0.8550 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5435 - val_accuracy: 0.8224 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 48/90\n",
      "32/32 [==============================] - 6s 186ms/step - loss: 0.4292 - accuracy: 0.8540 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5431 - val_accuracy: 0.8194 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 49/90\n",
      "32/32 [==============================] - 6s 187ms/step - loss: 0.4291 - accuracy: 0.8548 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5428 - val_accuracy: 0.8204 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 50/90\n",
      "32/32 [==============================] - 6s 185ms/step - loss: 0.4289 - accuracy: 0.8535 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5432 - val_accuracy: 0.8184 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 51/90\n",
      "32/32 [==============================] - 6s 182ms/step - loss: 0.4287 - accuracy: 0.8530 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5427 - val_accuracy: 0.8194 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 52/90\n",
      "32/32 [==============================] - 6s 183ms/step - loss: 0.4285 - accuracy: 0.8555 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5428 - val_accuracy: 0.8224 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 53/90\n",
      "32/32 [==============================] - 6s 186ms/step - loss: 0.4284 - accuracy: 0.8550 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5428 - val_accuracy: 0.8184 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 54/90\n",
      "32/32 [==============================] - 6s 189ms/step - loss: 0.4282 - accuracy: 0.8548 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5426 - val_accuracy: 0.8214 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 55/90\n",
      "32/32 [==============================] - 6s 184ms/step - loss: 0.4282 - accuracy: 0.8540 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5427 - val_accuracy: 0.8194 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 56/90\n",
      "32/32 [==============================] - 6s 184ms/step - loss: 0.4278 - accuracy: 0.8565 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5423 - val_accuracy: 0.8224 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 57/90\n",
      "32/32 [==============================] - 6s 185ms/step - loss: 0.4277 - accuracy: 0.8560 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5425 - val_accuracy: 0.8234 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 58/90\n",
      "32/32 [==============================] - 6s 190ms/step - loss: 0.4276 - accuracy: 0.8525 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5421 - val_accuracy: 0.8194 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 59/90\n",
      "32/32 [==============================] - 6s 188ms/step - loss: 0.4274 - accuracy: 0.8558 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5422 - val_accuracy: 0.8224 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 60/90\n",
      "32/32 [==============================] - 6s 186ms/step - loss: 0.4272 - accuracy: 0.8543 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5423 - val_accuracy: 0.8204 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 61/90\n",
      "32/32 [==============================] - 6s 183ms/step - loss: 0.4271 - accuracy: 0.8555 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5419 - val_accuracy: 0.8194 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 62/90\n",
      "32/32 [==============================] - 6s 187ms/step - loss: 0.4269 - accuracy: 0.8553 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5417 - val_accuracy: 0.8214 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 63/90\n",
      "32/32 [==============================] - 6s 185ms/step - loss: 0.4267 - accuracy: 0.8560 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5419 - val_accuracy: 0.8214 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 64/90\n",
      "32/32 [==============================] - 6s 185ms/step - loss: 0.4265 - accuracy: 0.8540 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5416 - val_accuracy: 0.8204 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 65/90\n",
      "32/32 [==============================] - 6s 185ms/step - loss: 0.4265 - accuracy: 0.8553 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5418 - val_accuracy: 0.8204 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 66/90\n",
      "32/32 [==============================] - 6s 187ms/step - loss: 0.4263 - accuracy: 0.8545 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5412 - val_accuracy: 0.8194 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 67/90\n",
      "32/32 [==============================] - 6s 192ms/step - loss: 0.4260 - accuracy: 0.8558 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5412 - val_accuracy: 0.8214 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 68/90\n",
      "32/32 [==============================] - 6s 186ms/step - loss: 0.4261 - accuracy: 0.8518 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5411 - val_accuracy: 0.8194 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 69/90\n",
      "32/32 [==============================] - 6s 184ms/step - loss: 0.4258 - accuracy: 0.8565 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5414 - val_accuracy: 0.8214 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 70/90\n",
      "32/32 [==============================] - 6s 183ms/step - loss: 0.4256 - accuracy: 0.8560 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5411 - val_accuracy: 0.8204 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 71/90\n",
      "32/32 [==============================] - 6s 190ms/step - loss: 0.4255 - accuracy: 0.8560 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5408 - val_accuracy: 0.8214 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 72/90\n",
      "32/32 [==============================] - 6s 194ms/step - loss: 0.4253 - accuracy: 0.8558 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5408 - val_accuracy: 0.8214 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 73/90\n",
      "32/32 [==============================] - 6s 185ms/step - loss: 0.4251 - accuracy: 0.8560 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5406 - val_accuracy: 0.8224 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 74/90\n",
      "32/32 [==============================] - 6s 182ms/step - loss: 0.4249 - accuracy: 0.8548 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5409 - val_accuracy: 0.8184 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 75/90\n",
      "32/32 [==============================] - 6s 186ms/step - loss: 0.4249 - accuracy: 0.8535 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5408 - val_accuracy: 0.8204 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 76/90\n",
      "32/32 [==============================] - 6s 186ms/step - loss: 0.4246 - accuracy: 0.8563 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5406 - val_accuracy: 0.8204 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 77/90\n",
      "32/32 [==============================] - 6s 190ms/step - loss: 0.4245 - accuracy: 0.8568 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5403 - val_accuracy: 0.8214 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 78/90\n",
      "32/32 [==============================] - 6s 185ms/step - loss: 0.4242 - accuracy: 0.8565 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5404 - val_accuracy: 0.8184 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 79/90\n",
      "32/32 [==============================] - 6s 183ms/step - loss: 0.4241 - accuracy: 0.8563 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5400 - val_accuracy: 0.8204 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 80/90\n",
      "32/32 [==============================] - 6s 189ms/step - loss: 0.4239 - accuracy: 0.8563 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5401 - val_accuracy: 0.8204 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 81/90\n",
      "32/32 [==============================] - 6s 190ms/step - loss: 0.4238 - accuracy: 0.8563 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5401 - val_accuracy: 0.8244 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 82/90\n",
      "32/32 [==============================] - 6s 180ms/step - loss: 0.4236 - accuracy: 0.8560 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5398 - val_accuracy: 0.8184 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 83/90\n",
      "32/32 [==============================] - 6s 180ms/step - loss: 0.4235 - accuracy: 0.8555 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5399 - val_accuracy: 0.8184 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 84/90\n",
      "32/32 [==============================] - 6s 180ms/step - loss: 0.4233 - accuracy: 0.8555 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5397 - val_accuracy: 0.8184 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 85/90\n",
      "32/32 [==============================] - 6s 180ms/step - loss: 0.4231 - accuracy: 0.8580 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5395 - val_accuracy: 0.8224 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 86/90\n",
      "32/32 [==============================] - 6s 180ms/step - loss: 0.4230 - accuracy: 0.8550 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5394 - val_accuracy: 0.8184 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 87/90\n",
      "32/32 [==============================] - 6s 184ms/step - loss: 0.4229 - accuracy: 0.8568 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5398 - val_accuracy: 0.8224 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 88/90\n",
      "32/32 [==============================] - 6s 183ms/step - loss: 0.4226 - accuracy: 0.8563 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5393 - val_accuracy: 0.8194 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 89/90\n",
      "32/32 [==============================] - 6s 180ms/step - loss: 0.4224 - accuracy: 0.8568 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5393 - val_accuracy: 0.8204 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n",
      "Epoch 90/90\n",
      "32/32 [==============================] - 6s 180ms/step - loss: 0.4223 - accuracy: 0.8558 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.5391 - val_accuracy: 0.8194 - val_top_k_categorical_accuracy: 0.9960 - lr: 1.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd00027d490>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training_images = tf.map_fn(lambda i: tf.stack([i]*3, axis=-1), training_images).numpy()\n",
    "# test_images = tf.map_fn(lambda i: tf.stack([i]*3, axis=-1), test_images).numpy()\n",
    "\n",
    "training_images = tf.image.resize(training_images, [224, 224]).numpy()\n",
    "test_images = tf.image.resize(test_images, [224, 224]).numpy()\n",
    "\n",
    "training_images = training_images.reshape(training_images.shape)\n",
    "training_images = training_images / 255.0\n",
    "test_images = test_images.reshape(test_images.shape)\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "training_labels = tf.keras.utils.to_categorical(training_labels, num_classes=len(training_classes))\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=len(test_classes))\n",
    "\n",
    "num_len_train = int(0.8 * len(training_images))\n",
    "\n",
    "ttraining_images = training_images[:num_len_train]\n",
    "ttraining_labels = training_labels[:num_len_train]\n",
    "\n",
    "valid_images = training_images[num_len_train:]\n",
    "valid_labels = training_labels[num_len_train:]\n",
    "\n",
    "training_images = ttraining_images\n",
    "training_labels = ttraining_labels\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "                                    \n",
    "\t\ttf.keras.layers.Conv2D(96, (7, 7), strides=(2, 2), activation='relu',\n",
    "\t\t\tinput_shape=(224, 224, 3)),\n",
    "\t\ttf.keras.layers.MaxPooling2D(3, strides=2),\n",
    "    tf.keras.layers.Lambda(lambda x: tf.image.per_image_standardization(x)),\n",
    "\n",
    "\t\ttf.keras.layers.Conv2D(256, (5, 5), strides=(2, 2), activation='relu'),\n",
    "\t\ttf.keras.layers.MaxPooling2D(3, strides=2),\n",
    "    tf.keras.layers.Lambda(lambda x: tf.image.per_image_standardization(x)),\n",
    "\n",
    "\t\ttf.keras.layers.Conv2D(384, (3, 3), activation='relu'),\n",
    "\n",
    "\t\ttf.keras.layers.Conv2D(384, (3, 3), activation='relu'),\n",
    "\n",
    "\t\ttf.keras.layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "\n",
    "\t\ttf.keras.layers.MaxPooling2D(3, strides=2),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "\n",
    "\t\ttf.keras.layers.Dense(4096),\n",
    "\n",
    "\t\ttf.keras.layers.Dense(4096),\n",
    "\n",
    "\t\ttf.keras.layers.Dense(len(classes), activation='softmax')#FIXME is this the number of classes? (check paper)\n",
    "\t])\n",
    "\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.01, momentum=0.9), \\\n",
    "              loss='categorical_crossentropy', \\\n",
    "              metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(5)])\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', \\\n",
    "                                            \t\tfactor=0.1, patience=1, \\\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tmin_lr=0.00001)\n",
    "model.fit(training_images, training_labels, batch_size=128, \\\n",
    "          validation_data=(valid_images, valid_labels), \\\n",
    "\t\t\t\t\tepochs=90, callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d43d1c-41ee-45f0-a341-3d2757eb5a12",
   "metadata": {},
   "source": [
    "## Evaluate the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7c21960-4a3d-46cb-8dfd-d3b8a8314ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_images shape: (1253, 224, 224, 3)\n",
      "test_labels shape: (1253, 8)\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.5503 - accuracy: 0.8148 - top_k_categorical_accuracy: 0.9992\n"
     ]
    }
   ],
   "source": [
    "print('test_images shape: {}'.format(test_images.shape))\n",
    "print('test_labels shape: {}'.format(test_labels.shape))\n",
    "\n",
    "results = model.evaluate(test_images,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18b52e25-9d06-4e81-b6c7-d317e158b35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 15ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = (model.predict(test_images) > 0.5).astype(\"int32\")\n",
    "# print(\"Predictions (shape: {}):\\n{}\".format(predictions.shape, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37a2dd7f-3232-4b86-84e0-4e4b7137660b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_classes: ['Kangaroo', 'Human Presense/Deployment', 'Empty photo', 'Emu', 'Fox', 'Rabbit', 'Other', 'Cat']\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "                      Cat       0.00      0.00      0.00         7\n",
      "              Empty photo       0.79      0.54      0.65       206\n",
      "                      Emu       0.82      0.76      0.79       136\n",
      "                      Fox       0.58      0.25      0.35        28\n",
      "Human Presense/Deployment       0.75      0.47      0.58       105\n",
      "                 Kangaroo       0.88      0.94      0.91       756\n",
      "                    Other       0.00      0.00      0.00        11\n",
      "                   Rabbit       0.00      0.00      0.00         4\n",
      "\n",
      "                micro avg       0.85      0.78      0.82      1253\n",
      "                macro avg       0.48      0.37      0.41      1253\n",
      "             weighted avg       0.83      0.78      0.80      1253\n",
      "              samples avg       0.78      0.78      0.78      1253\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"test_classes: {}\".format(test_classes))\n",
    "# classification_report uses alphabetic ordering of the classes, so to match the encoded labels to the target_names, provide a sortest list of classes\n",
    "# https://stackoverflow.com/a/48495303\n",
    "sorted_test_classes = sorted(test_classes)\n",
    "print(classification_report(test_labels, predictions, target_names=sorted_test_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738305b2-92f1-41c1-a4f2-07171823ec10",
   "metadata": {},
   "source": [
    "# Save the model\n",
    "* use the current date/time so we can keep incrementation progress of the model as we re-run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14e4681e-b9b8-419c-9cd5-bfd3b0a1763f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model as: 'ZFNet-29-05-2022_08:13:39.h5'.'\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "dt_string = now.strftime('%d-%m-%Y_%H:%M:%S')\n",
    "print(\"saving model as: 'ZFNet-{}.h5'.'\".format(dt_string))\n",
    "\n",
    "model.save('ZFNet-{}.h5'.format(dt_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006c0524-22ef-4ad4-8403-faec5dc9f5f4",
   "metadata": {},
   "source": [
    "## Free up the GPU's memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b4c59ac-35fd-420c-ab71-2dc2c7c457ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda.select_device(0)\n",
    "cuda.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25b0b019-ff12-4c7f-9278-3c16774e1262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# Counter(training_labels.tolist())\n",
    "# Counter(test_labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3426f494-49a1-4bac-a74f-35cb460b0175",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
