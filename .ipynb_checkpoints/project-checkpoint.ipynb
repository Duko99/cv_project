{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ad62cb3-b86d-4a0a-8492-ef09608a4c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fix last dense layer. Is it the number of classes? If so then nothing to fix\n",
    "# TODO: discuss how reading in dataset could be made multi-threaded (each dataset is read in on own thread then all joined together at the end)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import imageio as iio\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from numba import cuda  # https://stackoverflow.com/a/52354865/6476994\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "import re\n",
    "from datetime import datetime\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c4a177c-422b-48b4-b51f-ac05542a4e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# allows all images to be displayed at once (else only displays the last call to plt.imshow())\n",
    "# https://stackoverflow.com/a/41210974\n",
    "def displayImage(image, caption = None, colour = None) -> None:\n",
    "    plt.figure()\n",
    "    if(colour != None):\n",
    "        plt.imshow(image, cmap=colour)\n",
    "    else:\n",
    "        plt.imshow(image)\n",
    "        \n",
    "    if(caption != None):\n",
    "        # display caption below picture (https://stackoverflow.com/a/51486361)\n",
    "        plt.figtext(0.5, 0.01, caption, wrap=True, horizontalalignment='center', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7119a4c7-53e6-47b3-a57c-c8c54758002a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_names: ['BB01', 'BB02', 'BB03', 'BB04', 'BB05', 'BB06', 'BB07', 'BB08', 'BB09', 'BB10', 'BB11', 'BB12', 'BB13', 'BB14', 'BB15', 'BB16', 'BB17', 'BB18', 'BB19', 'BB20', 'BB21', 'BB22', 'BB23', 'BB24', 'BB25', 'BB26', 'BB27', 'BB28', 'BB29', 'BB30', 'BB31', 'BB32', 'BB33', 'BB34', 'BB35', 'BB36']\n"
     ]
    }
   ],
   "source": [
    "# dataset_names = [\"BB01\", \"BB02\", \"BB03\", \"BB04\", \"BB05\"]\n",
    "dataset_names = [\"BB01\", \"BB02\", \"BB03\", \"BB04\", \"BB05\", \"BB06\", \"BB07\", \"BB08\", \"BB09\", \"BB10\"]\n",
    "for i in range(11, 37):\n",
    "    dataset_names.append(\"BB{}\".format(i))\n",
    "print(\"dataset_names: {}\".format(dataset_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2162b806-d6bd-47ba-acc3-3f7209a27997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# free up GPU if it didn't after the last run\n",
    "cuda.select_device(0)\n",
    "cuda.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760dbfe7-ea61-44ed-bbbd-1d3d3b576c3f",
   "metadata": {},
   "source": [
    "# Read in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfbb46df-237c-4f68-b1af-5ee75f6b69b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading in images for dataset: BB01\n",
      "all_image_filenames length: 285\n",
      "done current dataset\n",
      "reading in images for dataset: BB02\n",
      "all_image_filenames length: 45\n",
      "done current dataset\n",
      "reading in images for dataset: BB03\n",
      "all_image_filenames length: 230\n",
      "done current dataset\n",
      "reading in images for dataset: BB04\n",
      "all_image_filenames length: 999\n",
      "done current dataset\n",
      "reading in images for dataset: BB05\n",
      "all_image_filenames length: 189\n",
      "done current dataset\n",
      "reading in images for dataset: BB06\n",
      "all_image_filenames length: 1137\n",
      "done current dataset\n",
      "reading in images for dataset: BB07\n",
      "all_image_filenames length: 324\n",
      "done current dataset\n",
      "reading in images for dataset: BB08\n",
      "all_image_filenames length: 66\n",
      "done current dataset\n",
      "reading in images for dataset: BB09\n",
      "all_image_filenames length: 357\n",
      "done current dataset\n",
      "reading in images for dataset: BB10\n",
      "all_image_filenames length: 121\n",
      "done current dataset\n",
      "reading in images for dataset: BB11\n",
      "all_image_filenames length: 167\n",
      "done current dataset\n",
      "reading in images for dataset: BB12\n",
      "all_image_filenames length: 157\n",
      "done current dataset\n",
      "reading in images for dataset: BB13\n",
      "all_image_filenames length: 50\n",
      "done current dataset\n",
      "reading in images for dataset: BB14\n",
      "all_image_filenames length: 367\n",
      "done current dataset\n",
      "reading in images for dataset: BB15\n",
      "all_image_filenames length: 91\n",
      "done current dataset\n",
      "reading in images for dataset: BB16\n",
      "all_image_filenames length: 213\n",
      "done current dataset\n",
      "reading in images for dataset: BB17\n",
      "all_image_filenames length: 26\n",
      "done current dataset\n",
      "reading in images for dataset: BB18\n",
      "all_image_filenames length: 75\n",
      "done current dataset\n",
      "reading in images for dataset: BB19\n",
      "all_image_filenames length: 72\n",
      "done current dataset\n",
      "reading in images for dataset: BB20\n",
      "all_image_filenames length: 96\n",
      "done current dataset\n",
      "reading in images for dataset: BB21\n",
      "all_image_filenames length: 78\n",
      "done current dataset\n",
      "reading in images for dataset: BB22\n",
      "all_image_filenames length: 123\n",
      "done current dataset\n",
      "reading in images for dataset: BB23\n",
      "all_image_filenames length: 192\n",
      "done current dataset\n",
      "reading in images for dataset: BB24\n",
      "all_image_filenames length: 62\n",
      "done current dataset\n",
      "reading in images for dataset: BB25\n",
      "all_image_filenames length: 10\n",
      "done current dataset\n",
      "reading in images for dataset: BB26\n",
      "all_image_filenames length: 142\n",
      "done current dataset\n",
      "reading in images for dataset: BB27\n",
      "all_image_filenames length: 46\n",
      "done current dataset\n",
      "reading in images for dataset: BB28\n",
      "all_image_filenames length: 73\n",
      "done current dataset\n",
      "reading in images for dataset: BB29\n",
      "all_image_filenames length: 20\n",
      "done current dataset\n",
      "reading in images for dataset: BB30\n",
      "all_image_filenames length: 450\n",
      "done current dataset\n",
      "reading in images for dataset: BB31\n",
      "all_image_filenames length: 42\n",
      "done current dataset\n",
      "reading in images for dataset: BB32\n",
      "all_image_filenames length: 268\n",
      "done current dataset\n",
      "reading in images for dataset: BB33\n",
      "all_image_filenames length: 136\n",
      "done current dataset\n",
      "reading in images for dataset: BB34\n",
      "all_image_filenames length: 127\n",
      "done current dataset\n",
      "reading in images for dataset: BB35\n",
      "all_image_filenames length: 45\n",
      "done current dataset\n",
      "reading in images for dataset: BB36\n",
      "all_image_filenames length: 108\n",
      "done current dataset\n"
     ]
    }
   ],
   "source": [
    "# get the all original output filenames\n",
    "def readInImages(datasetName):\n",
    "    print(\"reading in images for dataset: {}\".format(datasetName))\n",
    "    desired_size = 224\n",
    "    image_list = []\n",
    "    imgRegExp = re.compile(r'.*[.](JPG)$')\n",
    "    # https://stackoverflow.com/a/3207973\n",
    "    all_image_filenames = next(os.walk('data/{}'.format(datasetName)),\n",
    "                         (None, None, []))[2]  # [] if no file\n",
    "    # filter out file names that are not JPEGs\n",
    "    all_image_filenames = [i for i in all_image_filenames if imgRegExp.match(i)]\n",
    "    # walk() outputs unordered, so we need to sort\n",
    "    all_image_filenames.sort()\n",
    "    # print(\"all_image_filenames: {}\".format(all_image_filenames))\n",
    "    print(\"all_image_filenames length: {}\".format(len(all_image_filenames)))\n",
    "    for fn in all_image_filenames:\n",
    "        # im = Image.open('data/{}/{}'.format(datasetName, fn))\n",
    "        im = cv2.imread('data/{}/{}'.format(datasetName, fn))\n",
    "        # resize the image to conserve memory, and transform it to be square while\n",
    "        # maintaining the aspect ration (give it padding):\n",
    "        # https://jdhao.github.io/2017/11/06/resize-image-to-square-with-padding/#using-opencv\n",
    "        old_size = im.shape[:2]\n",
    "        ratio = float(desired_size)/max(old_size)\n",
    "        new_size = tuple([int(x*ratio) for x in old_size])\n",
    "        im = cv2.resize(im, (new_size[1], new_size[0]))\n",
    "\n",
    "        delta_w = desired_size - new_size[1]\n",
    "        delta_h = desired_size - new_size[0]\n",
    "        top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "        left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "\n",
    "        color = [0, 0, 0]\n",
    "        new_im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)\n",
    "\n",
    "        \n",
    "        image_list.append(np.asarray(new_im))\n",
    "    \n",
    "    print(\"done current dataset\")\n",
    "    return image_list\n",
    "\n",
    "all_images = []\n",
    "for fn in dataset_names:    \n",
    "    all_images = [*all_images, *readInImages(fn)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aded9195-def1-48e6-bb54-4062ec01dc5b",
   "metadata": {},
   "source": [
    "# Read in dataset's labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d14a993b-efcc-4927-b522-44cbb90e8295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all classes (length=8): {'Kangaroo', 'Emu', 'Cat', 'Human Presense/Deployment', 'Empty photo', 'Other', 'Rabbit', 'Fox'}\n"
     ]
    }
   ],
   "source": [
    "# labels (using dataset's CSV file)\n",
    "\n",
    "def readInAnnotations(datasetName):\n",
    "    labelList = []\n",
    "    # https://realpython.com/python-csv/#reading-csv-files-with-csv\n",
    "    with open('data/{}/{}.csv'.format(datasetName, datasetName)) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        line_count = 0\n",
    "        for row in csv_reader:\n",
    "            # print(\"row: {}\".format(row))\n",
    "            # first row always contains this string, so ignore it\n",
    "            if \"RECONYX - MapView Professional\" in row:\n",
    "                continue\n",
    "            if line_count == 0:\n",
    "                # print(f'Column names are {\", \".join(row)}')\n",
    "                line_count += 1\n",
    "            else:\n",
    "                # print(\"Image Name: {}. Hit List: {}\".format(row[0], row[22].replace(\"\\n\", \", \")))\n",
    "                # FIXME handle when hitlist contains more than one item (e.g., BB06 IMG_512 has 'kangaroo' and 'empty photo') - sort of handled, need to make more dynamic\n",
    "                hit_list = row[22]\n",
    "                if hit_list == '':\n",
    "                    labelList.append(\"Empty photo\")\n",
    "                elif hit_list == 'Empty photo\\nHuman Presense/Deployment':\n",
    "                    labelList.append(\"Human Presense/Deployment\")\n",
    "                elif hit_list == 'Kangaroo\\nEmpty photo':\n",
    "                    labelList.append(\"Kangaroo\")\n",
    "                else:\n",
    "                    # FIXME: rendundant case?\n",
    "                    labelList.append(hit_list.replace(\"\\n\", \", \"))\n",
    "                line_count += 1\n",
    "    # print(\"returning labelList (length: {}): {}\".format(len(labelList), labelList))\n",
    "    # print(\"returning labelList of length: {}\".format(len(labelList)))\n",
    "    return labelList\n",
    "\n",
    "all_image_labels = []\n",
    "for fn in dataset_names:\n",
    "    all_image_labels = [*all_image_labels, *readInAnnotations(fn)]\n",
    "\n",
    "# print(\"all_image_labels: {}\".format(all_image_labels))\n",
    "\n",
    "classes = set(all_image_labels)\n",
    "print(\"all classes (length={}): {}\".format(len(classes), classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f21c8c-b002-41c6-8ee5-8c249bc7f2aa",
   "metadata": {},
   "source": [
    "# Randomly split the dataset and corresponding labels into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44e9f9bb-0adf-4b24-8bb7-6607dccd3ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_images size: 6989\n",
      "training_labels length: 5591\n",
      "test_labels length: 1398\n",
      "counter: Counter({'Kangaroo': 870, 'Empty photo': 227, 'Emu': 119, 'Human Presense/Deployment': 110, 'Fox': 33, 'Cat': 16, 'Other': 16, 'Rabbit': 7})\n",
      "training_classes (length=8): ['Human Presense/Deployment', 'Empty photo', 'Emu', 'Kangaroo', 'Other', 'Rabbit', 'Fox', 'Cat']\n",
      "test_classes (length=8): ['Human Presense/Deployment', 'Kangaroo', 'Empty photo', 'Fox', 'Emu', 'Cat', 'Rabbit', 'Other']\n",
      "done stacking\n",
      "training_images shape: (5591, 224, 224, 3)\n",
      "test_images shape: (1398, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"all_images size: {}\".format(len(all_images)))\n",
    "# print(\"all_image_labels size: {}\".format(len(all_image_labels)))\n",
    "\n",
    "\n",
    "training_images, test_images, training_labels, test_labels = train_test_split(all_images, all_image_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"training_labels length: {}\".format(len(training_labels)))\n",
    "print(\"test_labels length: {}\".format(len(test_labels)))\n",
    "# print(\"test_labels: {}\".format(test_labels))\n",
    "counter = collections.Counter(test_labels)\n",
    "print(\"counter: {}\".format(counter))\n",
    "\n",
    "# training_classes = set(training_labels)\n",
    "training_classes = []\n",
    "for label in training_labels:\n",
    "    if label not in training_classes:\n",
    "        training_classes.append(label)\n",
    "# test_classes = set(test_labels)\n",
    "test_classes = []\n",
    "for label in test_labels:\n",
    "    if label not in test_classes:\n",
    "        test_classes.append(label)\n",
    "print(\"training_classes (length={}): {}\".format(len(training_classes), training_classes))\n",
    "print(\"test_classes (length={}): {}\".format(len(test_classes), test_classes))\n",
    "\n",
    "# integer-encode labels so they can be one-hot-encoded\n",
    "# https://stackoverflow.com/a/56227965/6476994\n",
    "label_encoder = LabelEncoder()\n",
    "training_labels = np.array(training_labels)\n",
    "training_labels = label_encoder.fit_transform(training_labels)\n",
    "test_labels = np.array(test_labels)\n",
    "test_labels = label_encoder.fit_transform(test_labels)\n",
    "\n",
    "\n",
    "# convert list of numpy arrays to numpy array of numpy arrays\n",
    "# https://stackoverflow.com/a/27516930/6476994\n",
    "training_images = np.stack(training_images, axis = 0)\n",
    "test_images = np.stack(test_images, axis = 0)\n",
    "\n",
    "print(\"done stacking\")\n",
    "print(\"training_images shape: {}\".format(training_images.shape))\n",
    "print(\"test_images shape: {}\".format(test_images.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de40603-e6cd-4c93-856c-eed237c3f7dc",
   "metadata": {},
   "source": [
    "# ZFNet\n",
    "\n",
    "Source: https://towardsdatascience.com/zfnet-an-explanation-of-paper-with-code-f1bd6752121d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da469ee2-ad90-402b-9b57-55a1388138e3",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d882d77-9109-494a-8c37-7ee3518adf8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-29 08:23:49.908454: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-29 08:23:49.913987: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-29 08:23:49.914252: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-29 08:23:49.915033: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-29 08:23:49.915437: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-29 08:23:49.915587: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-29 08:23:49.915721: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-29 08:23:50.247514: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-29 08:23:50.247777: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-29 08:23:50.247919: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-29 08:23:50.248042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5257 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070, pci bus id: 0000:2b:00.0, compute capability: 7.5\n",
      "2022-05-29 08:23:50.760008: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 3366408192 exceeds 10% of free system memory.\n",
      "/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "2022-05-29 08:23:53.608498: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2692644864 exceeds 10% of free system memory.\n",
      "2022-05-29 08:23:54.477646: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2692644864 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-29 08:23:56.131548: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2022-05-29 08:23:56.507399: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2022-05-29 08:23:56.594263: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 868.79MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-05-29 08:23:56.594293: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 868.79MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-05-29 08:23:57.290183: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.01GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-05-29 08:23:57.290210: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.01GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-05-29 08:23:57.553121: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.01GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-05-29 08:23:57.553148: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.01GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-05-29 08:23:58.217353: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 982.19MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-05-29 08:23:58.217412: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 982.19MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/35 [============================>.] - ETA: 0s - loss: 1.5550 - accuracy: 0.5200 - top_k_categorical_accuracy: 0.9704"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-29 08:24:04.674359: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1010.50MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-05-29 08:24:04.674388: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1010.50MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 12s 254ms/step - loss: 1.5448 - accuracy: 0.5228 - top_k_categorical_accuracy: 0.9703 - val_loss: 1.1332 - val_accuracy: 0.6104 - val_top_k_categorical_accuracy: 0.9803 - lr: 0.0100\n",
      "Epoch 2/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-29 08:24:17.317171: W tensorflow/core/common_runtime/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 136.69MiB (rounded to 143327232)requested by op gradient_tape/sequential/conv2d_1/Conv2D/Conv2DBackpropInput\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2022-05-29 08:24:17.317207: I tensorflow/core/common_runtime/bfc_allocator.cc:1027] BFCAllocator dump for GPU_0_bfc\n",
      "2022-05-29 08:24:17.317218: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (256): \tTotal Chunks: 50, Chunks in use: 49. 12.5KiB allocated for chunks. 12.2KiB in use in bin. 416B client-requested in use in bin.\n",
      "2022-05-29 08:24:17.317226: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (512): \tTotal Chunks: 4, Chunks in use: 4. 2.0KiB allocated for chunks. 2.0KiB in use in bin. 1.8KiB client-requested in use in bin.\n",
      "2022-05-29 08:24:17.317234: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (1024): \tTotal Chunks: 10, Chunks in use: 9. 12.2KiB allocated for chunks. 11.2KiB in use in bin. 11.0KiB client-requested in use in bin.\n",
      "2022-05-29 08:24:17.317241: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-05-29 08:24:17.317247: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (4096): \tTotal Chunks: 1, Chunks in use: 0. 5.5KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-05-29 08:24:17.317253: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-05-29 08:24:17.317261: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (16384): \tTotal Chunks: 4, Chunks in use: 4. 64.0KiB allocated for chunks. 64.0KiB in use in bin. 64.0KiB client-requested in use in bin.\n",
      "2022-05-29 08:24:17.317268: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (32768): \tTotal Chunks: 2, Chunks in use: 2. 90.2KiB allocated for chunks. 90.2KiB in use in bin. 90.1KiB client-requested in use in bin.\n",
      "2022-05-29 08:24:17.317276: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (65536): \tTotal Chunks: 1, Chunks in use: 1. 66.8KiB allocated for chunks. 66.8KiB in use in bin. 55.1KiB client-requested in use in bin.\n",
      "2022-05-29 08:24:17.317283: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (131072): \tTotal Chunks: 2, Chunks in use: 2. 256.0KiB allocated for chunks. 256.0KiB in use in bin. 256.0KiB client-requested in use in bin.\n",
      "2022-05-29 08:24:17.317291: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (262144): \tTotal Chunks: 1, Chunks in use: 1. 256.0KiB allocated for chunks. 256.0KiB in use in bin. 139.8KiB client-requested in use in bin.\n",
      "2022-05-29 08:24:17.317297: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-05-29 08:24:17.317303: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-05-29 08:24:17.317311: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (2097152): \tTotal Chunks: 6, Chunks in use: 6. 17.81MiB allocated for chunks. 17.81MiB in use in bin. 17.16MiB client-requested in use in bin.\n",
      "2022-05-29 08:24:17.317318: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (4194304): \tTotal Chunks: 3, Chunks in use: 3. 16.50MiB allocated for chunks. 16.50MiB in use in bin. 13.50MiB client-requested in use in bin.\n",
      "2022-05-29 08:24:17.317325: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (8388608): \tTotal Chunks: 1, Chunks in use: 0. 15.55MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-05-29 08:24:17.317332: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (16777216): \tTotal Chunks: 2, Chunks in use: 2. 44.62MiB allocated for chunks. 44.62MiB in use in bin. 32.00MiB client-requested in use in bin.\n",
      "2022-05-29 08:24:17.317339: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (33554432): \tTotal Chunks: 1, Chunks in use: 0. 36.07MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-05-29 08:24:17.317348: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (67108864): \tTotal Chunks: 6, Chunks in use: 4. 495.23MiB allocated for chunks. 343.61MiB in use in bin. 279.62MiB client-requested in use in bin.\n",
      "2022-05-29 08:24:17.317356: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (134217728): \tTotal Chunks: 4, Chunks in use: 4. 605.71MiB allocated for chunks. 605.71MiB in use in bin. 546.75MiB client-requested in use in bin.\n",
      "2022-05-29 08:24:17.317363: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (268435456): \tTotal Chunks: 4, Chunks in use: 4. 3.93GiB allocated for chunks. 3.93GiB in use in bin. 3.81GiB client-requested in use in bin.\n",
      "2022-05-29 08:24:17.317396: I tensorflow/core/common_runtime/bfc_allocator.cc:1050] Bin for 136.69MiB was 128.00MiB, Chunk State: \n",
      "2022-05-29 08:24:17.317402: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] Next region of size 5513347072\n",
      "2022-05-29 08:24:17.317412: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d8e000000 of size 256 next 3\n",
      "2022-05-29 08:24:17.317417: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d8e000100 of size 256 next 4\n",
      "2022-05-29 08:24:17.317422: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d8e000200 of size 256 next 5\n",
      "2022-05-29 08:24:17.317427: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d8e000300 of size 256 next 6\n",
      "2022-05-29 08:24:17.317433: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d8e000400 of size 512 next 7\n",
      "2022-05-29 08:24:17.317438: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d8e000600 of size 256 next 10\n",
      "2022-05-29 08:24:17.317443: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d8e000700 of size 256 next 11\n",
      "2022-05-29 08:24:17.317448: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d8e000800 of size 1024 next 12\n",
      "2022-05-29 08:24:17.317454: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d8e000c00 of size 256 next 15\n",
      "2022-05-29 08:24:17.317459: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d8e000d00 of size 256 next 16\n",
      "2022-05-29 08:24:17.317464: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d8e000e00 of size 1536 next 19\n",
      "2022-05-29 08:24:17.317469: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d8e001400 of size 256 next 20\n",
      "2022-05-29 08:24:17.317474: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d8e001500 of size 256 next 21\n",
      "2022-05-29 08:24:17.317479: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d8e001600 of size 1536 next 22\n",
      "2022-05-29 08:24:17.317484: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d8e001c00 of size 1024 next 26\n",
      "2022-05-29 08:24:17.317489: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d8e002000 of size 256 next 27\n",
      "2022-05-29 08:24:17.317494: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d8e002100 of size 256 next 28\n",
      "2022-05-29 08:24:17.317499: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d8e002200 of size 16384 next 29\n",
      "2022-05-29 08:24:17.317504: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d8e006200 of size 256 next 32\n",
      "2022-05-29 08:24:17.317509: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d8e006300 of size 256 next 33\n",
      "2022-05-29 08:24:17.317514: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d8e006400 of size 16384 next 34\n",
      "2022-05-29 08:24:17.317519: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d8e00a400 of size 256 next 37\n",
      "2022-05-29 08:24:17.317524: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d8e00a500 of size 256 next 38\n",
      "2022-05-29 08:24:17.317529: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d8e00a600 of size 256 next 39\n",
      "2022-05-29 08:24:17.317535: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d8e00a700 of size 256 next 42\n",
      "2022-05-29 08:24:17.317540: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d8e00a800 of size 256 next 43\n",
      "2022-05-29 08:24:17.317545: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d8e00a900 of size 256 next 44\n",
      "2022-05-29 08:24:17.317550: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d8e00aa00 of size 256 next 45\n",
      "2022-05-29 08:24:17.317555: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d8e00ab00 of size 256 next 46\n",
      "2022-05-29 08:24:17.317560: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d8e00ac00 of size 256 next 48\n",
      "2022-05-29 08:24:17.317565: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d8e00ad00 of size 256 next 49\n",
      "2022-05-29 08:24:17.317570: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d8e00ae00 of size 256 next 50\n",
      "2022-05-29 08:24:17.317575: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d8e00af00 of size 256 next 51\n",
      "2022-05-29 08:24:17.317580: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d8e00b000 of size 256 next 52\n",
      "2022-05-29 08:24:17.317585: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d8e00b100 of size 256 next 53\n",
      "2022-05-29 08:24:17.317590: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d8e00b200 of size 256 next 54\n",
      "2022-05-29 08:24:17.317595: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d8e00b300 of size 68352 next 8\n",
      "2022-05-29 08:24:17.317601: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d8e01be00 of size 56576 next 9\n",
      "2022-05-29 08:24:17.317606: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d8e029b00 of size 1024 next 56\n",
      "2022-05-29 08:24:17.317611: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d8e029f00 of size 4914176 next 14\n",
      "2022-05-29 08:24:17.317616: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d8e4d9b00 of size 2457600 next 13\n",
      "2022-05-29 08:24:17.317622: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d8e731b00 of size 262144 next 41\n",
      "2022-05-29 08:24:17.317627: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d8e771b00 of size 131072 next 40\n",
      "2022-05-29 08:24:17.317632: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d8e791b00 of size 512 next 55\n",
      "2022-05-29 08:24:17.317638: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d8e791d00 of size 3145216 next 18\n",
      "2022-05-29 08:24:17.317643: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d8ea91b00 of size 3538944 next 17\n",
      "2022-05-29 08:24:17.317648: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d8edf1b00 of size 3538944 next 25\n",
      "2022-05-29 08:24:17.317653: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d8f151b00 of size 1536 next 57\n",
      "2022-05-29 08:24:17.317658: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d8f152100 of size 7076352 next 24\n",
      "2022-05-29 08:24:17.317663: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d8f811b00 of size 5308416 next 23\n",
      "2022-05-29 08:24:17.317668: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d8fd21b00 of size 1536 next 58\n",
      "2022-05-29 08:24:17.317673: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d8fd22100 of size 3538944 next 59\n",
      "2022-05-29 08:24:17.317678: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d90082100 of size 1024 next 60\n",
      "2022-05-29 08:24:17.317684: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d90082500 of size 30012928 next 31\n",
      "2022-05-29 08:24:17.317689: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d91d21b00 of size 16777216 next 30\n",
      "2022-05-29 08:24:17.317694: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d92d21b00 of size 16384 next 61\n",
      "2022-05-29 08:24:17.317700: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d92d25b00 of size 134201344 next 36\n",
      "2022-05-29 08:24:17.317705: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d9ad21b00 of size 67108864 next 35\n",
      "2022-05-29 08:24:17.317711: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d9ed21b00 of size 16384 next 62\n",
      "2022-05-29 08:24:17.317716: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d9ed25b00 of size 131072 next 63\n",
      "2022-05-29 08:24:17.317721: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d9ed45b00 of size 256 next 64\n",
      "2022-05-29 08:24:17.317726: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d9ed45c00 of size 256 next 65\n",
      "2022-05-29 08:24:17.317731: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d9ed45d00 of size 256 next 66\n",
      "2022-05-29 08:24:17.317736: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d9ed45e00 of size 256 next 67\n",
      "2022-05-29 08:24:17.317741: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d9ed45f00 of size 256 next 68\n",
      "2022-05-29 08:24:17.317746: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d9ed46000 of size 256 next 69\n",
      "2022-05-29 08:24:17.317751: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d9ed46100 of size 256 next 70\n",
      "2022-05-29 08:24:17.317756: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6d9ed46200 of size 256 next 71\n",
      "2022-05-29 08:24:17.317761: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f6d9ed46300 of size 37820928 next 74\n",
      "2022-05-29 08:24:17.317766: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6da1157d00 of size 256 next 80\n",
      "2022-05-29 08:24:17.317771: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6da1157e00 of size 256 next 89\n",
      "2022-05-29 08:24:17.317776: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6da1157f00 of size 256 next 82\n",
      "2022-05-29 08:24:17.317781: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6da1158000 of size 35840 next 117\n",
      "2022-05-29 08:24:17.317786: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6da1160c00 of size 256 next 113\n",
      "2022-05-29 08:24:17.317791: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6da1160d00 of size 256 next 120\n",
      "2022-05-29 08:24:17.317796: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f6da1160e00 of size 5632 next 100\n",
      "2022-05-29 08:24:17.317801: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6da1162400 of size 512 next 76\n",
      "2022-05-29 08:24:17.317806: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6da1162600 of size 512 next 84\n",
      "2022-05-29 08:24:17.317811: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6da1162800 of size 256 next 112\n",
      "2022-05-29 08:24:17.317816: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6da1162900 of size 256 next 88\n",
      "2022-05-29 08:24:17.317821: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6da1162a00 of size 256 next 103\n",
      "2022-05-29 08:24:17.317826: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f6da1162b00 of size 1024 next 72\n",
      "2022-05-29 08:24:17.317831: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6da1162f00 of size 256 next 114\n",
      "2022-05-29 08:24:17.317836: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6da1163000 of size 2457600 next 101\n",
      "2022-05-29 08:24:17.317841: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f6da13bb000 of size 16305664 next 95\n",
      "2022-05-29 08:24:17.317846: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6da2347e00 of size 256 next 97\n",
      "2022-05-29 08:24:17.317851: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6da2347f00 of size 256 next 83\n",
      "2022-05-29 08:24:17.317856: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f6da2348000 of size 256 next 115\n",
      "2022-05-29 08:24:17.317861: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6da2348100 of size 256 next 75\n",
      "2022-05-29 08:24:17.317866: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f6da2348200 of size 77070336 next 106\n",
      "2022-05-29 08:24:17.317872: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6da6cc8200 of size 77070336 next 94\n",
      "2022-05-29 08:24:17.317877: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6dab648200 of size 143327232 next 86\n",
      "2022-05-29 08:24:17.317882: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6db3ef8200 of size 205148672 next 1\n",
      "2022-05-29 08:24:17.317888: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6dc029d400 of size 1280 next 2\n",
      "2022-05-29 08:24:17.317893: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6dc029d900 of size 2692644864 next 47\n",
      "2022-05-29 08:24:17.317898: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6e60a85900 of size 673763328 next 98\n",
      "2022-05-29 08:24:17.317904: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6e88d12900 of size 583974912 next 78\n",
      "2022-05-29 08:24:17.317909: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6eab9fe900 of size 143327232 next 96\n",
      "2022-05-29 08:24:17.317914: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6eb42ae900 of size 143327232 next 99\n",
      "2022-05-29 08:24:17.317919: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f6ebcb5e900 of size 81920000 next 73\n",
      "2022-05-29 08:24:17.317924: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6ec197e900 of size 81920000 next 118\n",
      "2022-05-29 08:24:17.317930: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6ec679e900 of size 270866176 next 18446744073709551615\n",
      "2022-05-29 08:24:17.317934: I tensorflow/core/common_runtime/bfc_allocator.cc:1088]      Summary of in-use Chunks by size: \n",
      "2022-05-29 08:24:17.317941: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 49 Chunks of size 256 totalling 12.2KiB\n",
      "2022-05-29 08:24:17.317948: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 4 Chunks of size 512 totalling 2.0KiB\n",
      "2022-05-29 08:24:17.317953: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 4 Chunks of size 1024 totalling 4.0KiB\n",
      "2022-05-29 08:24:17.317959: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2022-05-29 08:24:17.317965: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 4 Chunks of size 1536 totalling 6.0KiB\n",
      "2022-05-29 08:24:17.317971: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 4 Chunks of size 16384 totalling 64.0KiB\n",
      "2022-05-29 08:24:17.317977: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 35840 totalling 35.0KiB\n",
      "2022-05-29 08:24:17.317983: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 56576 totalling 55.2KiB\n",
      "2022-05-29 08:24:17.317989: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 68352 totalling 66.8KiB\n",
      "2022-05-29 08:24:17.317995: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 2 Chunks of size 131072 totalling 256.0KiB\n",
      "2022-05-29 08:24:17.318000: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 262144 totalling 256.0KiB\n",
      "2022-05-29 08:24:17.318006: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 2 Chunks of size 2457600 totalling 4.69MiB\n",
      "2022-05-29 08:24:17.318012: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 3145216 totalling 3.00MiB\n",
      "2022-05-29 08:24:17.318018: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 3 Chunks of size 3538944 totalling 10.12MiB\n",
      "2022-05-29 08:24:17.318024: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 4914176 totalling 4.69MiB\n",
      "2022-05-29 08:24:17.318030: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 5308416 totalling 5.06MiB\n",
      "2022-05-29 08:24:17.318035: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 7076352 totalling 6.75MiB\n",
      "2022-05-29 08:24:17.318041: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 16777216 totalling 16.00MiB\n",
      "2022-05-29 08:24:17.318047: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 30012928 totalling 28.62MiB\n",
      "2022-05-29 08:24:17.318053: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 67108864 totalling 64.00MiB\n",
      "2022-05-29 08:24:17.318059: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 77070336 totalling 73.50MiB\n",
      "2022-05-29 08:24:17.318065: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 81920000 totalling 78.12MiB\n",
      "2022-05-29 08:24:17.318071: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 134201344 totalling 127.98MiB\n",
      "2022-05-29 08:24:17.318077: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 3 Chunks of size 143327232 totalling 410.06MiB\n",
      "2022-05-29 08:24:17.318083: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 205148672 totalling 195.64MiB\n",
      "2022-05-29 08:24:17.318089: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 270866176 totalling 258.32MiB\n",
      "2022-05-29 08:24:17.318095: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 583974912 totalling 556.92MiB\n",
      "2022-05-29 08:24:17.318101: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 673763328 totalling 642.55MiB\n",
      "2022-05-29 08:24:17.318106: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 2692644864 totalling 2.51GiB\n",
      "2022-05-29 08:24:17.318112: I tensorflow/core/common_runtime/bfc_allocator.cc:1095] Sum Total of in-use chunks: 4.94GiB\n",
      "2022-05-29 08:24:17.318118: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] total_region_allocated_bytes_: 5513347072 memory_limit_: 5513347072 available bytes: 0 curr_region_allocation_bytes_: 11026694144\n",
      "2022-05-29 08:24:17.318127: I tensorflow/core/common_runtime/bfc_allocator.cc:1103] Stats: \n",
      "Limit:                      5513347072\n",
      "InUse:                      5300223232\n",
      "MaxInUse:                   5513342464\n",
      "NumAllocs:                        7751\n",
      "MaxAllocSize:               2692644864\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2022-05-29 08:24:17.318137: W tensorflow/core/common_runtime/bfc_allocator.cc:491] **************************************************************************************************xx\n",
      "2022-05-29 08:24:17.318169: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at conv_grad_input_ops.cc:326 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[128,96,54,54] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'gradient_tape/sequential/conv2d_1/Conv2D/Conv2DBackpropInput' defined at (most recent call last):\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/traitlets/config/application.py\", line 972, in launch_instance\n      app.start()\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 504, in dispatch_queue\n      await self.process_one()\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 493, in process_one\n      await dispatch(*args)\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 400, in dispatch_shell\n      await result\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 724, in execute_request\n      reply_content = await reply_content\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2880, in run_cell\n      result = self._run_cell(\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2935, in _run_cell\n      return runner(coro)\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3134, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3337, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3397, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_41608/1548013456.py\", line 62, in <cell line: 62>\n      model.fit(training_images, training_labels, batch_size=128, \\\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/keras/engine/training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/keras/engine/training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/keras/engine/training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/keras/engine/training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/keras/engine/training.py\", line 893, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\", line 537, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\", line 590, in _compute_gradients\n      grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\", line 471, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/sequential/conv2d_1/Conv2D/Conv2DBackpropInput'\nOOM when allocating tensor with shape[128,96,54,54] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/sequential/conv2d_1/Conv2D/Conv2DBackpropInput}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_1535]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 62>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mSGD(lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m), \\\n\u001b[1;32m     56\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, \\\n\u001b[1;32m     57\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mTopKCategoricalAccuracy(\u001b[38;5;241m5\u001b[39m)])\n\u001b[1;32m     59\u001b[0m reduce_lr \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, \\\n\u001b[1;32m     60\u001b[0m                                             \t\tfactor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, \\\n\u001b[1;32m     61\u001b[0m \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tmin_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.00001\u001b[39m)\n\u001b[0;32m---> 62\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalid_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m\t\t\t\t\t\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m90\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'gradient_tape/sequential/conv2d_1/Conv2D/Conv2DBackpropInput' defined at (most recent call last):\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/traitlets/config/application.py\", line 972, in launch_instance\n      app.start()\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 504, in dispatch_queue\n      await self.process_one()\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 493, in process_one\n      await dispatch(*args)\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 400, in dispatch_shell\n      await result\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 724, in execute_request\n      reply_content = await reply_content\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2880, in run_cell\n      result = self._run_cell(\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2935, in _run_cell\n      return runner(coro)\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3134, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3337, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3397, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_41608/1548013456.py\", line 62, in <cell line: 62>\n      model.fit(training_images, training_labels, batch_size=128, \\\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/keras/engine/training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/keras/engine/training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/keras/engine/training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/keras/engine/training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/keras/engine/training.py\", line 893, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\", line 537, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\", line 590, in _compute_gradients\n      grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)\n    File \"/home/luke/miniconda3/envs/cv-project-env/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\", line 471, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/sequential/conv2d_1/Conv2D/Conv2DBackpropInput'\nOOM when allocating tensor with shape[128,96,54,54] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/sequential/conv2d_1/Conv2D/Conv2DBackpropInput}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_1535]"
     ]
    }
   ],
   "source": [
    "# training_images = tf.map_fn(lambda i: tf.stack([i]*3, axis=-1), training_images).numpy()\n",
    "# test_images = tf.map_fn(lambda i: tf.stack([i]*3, axis=-1), test_images).numpy()\n",
    "\n",
    "training_images = tf.image.resize(training_images, [224, 224]).numpy()\n",
    "test_images = tf.image.resize(test_images, [224, 224]).numpy()\n",
    "\n",
    "training_images = training_images.reshape(training_images.shape)\n",
    "training_images = training_images / 255.0\n",
    "test_images = test_images.reshape(test_images.shape)\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "training_labels = tf.keras.utils.to_categorical(training_labels, num_classes=len(training_classes))\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=len(test_classes))\n",
    "\n",
    "num_len_train = int(0.8 * len(training_images))\n",
    "\n",
    "ttraining_images = training_images[:num_len_train]\n",
    "ttraining_labels = training_labels[:num_len_train]\n",
    "\n",
    "valid_images = training_images[num_len_train:]\n",
    "valid_labels = training_labels[num_len_train:]\n",
    "\n",
    "training_images = ttraining_images\n",
    "training_labels = ttraining_labels\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "                                    \n",
    "\t\ttf.keras.layers.Conv2D(96, (7, 7), strides=(2, 2), activation='relu',\n",
    "\t\t\tinput_shape=(224, 224, 3)),\n",
    "\t\ttf.keras.layers.MaxPooling2D(3, strides=2),\n",
    "    tf.keras.layers.Lambda(lambda x: tf.image.per_image_standardization(x)),\n",
    "\n",
    "\t\ttf.keras.layers.Conv2D(256, (5, 5), strides=(2, 2), activation='relu'),\n",
    "\t\ttf.keras.layers.MaxPooling2D(3, strides=2),\n",
    "    tf.keras.layers.Lambda(lambda x: tf.image.per_image_standardization(x)),\n",
    "\n",
    "\t\ttf.keras.layers.Conv2D(384, (3, 3), activation='relu'),\n",
    "\n",
    "\t\ttf.keras.layers.Conv2D(384, (3, 3), activation='relu'),\n",
    "\n",
    "\t\ttf.keras.layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "\n",
    "\t\ttf.keras.layers.MaxPooling2D(3, strides=2),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "\n",
    "\t\ttf.keras.layers.Dense(4096),\n",
    "\n",
    "\t\ttf.keras.layers.Dense(4096),\n",
    "\n",
    "\t\ttf.keras.layers.Dense(len(classes), activation='softmax')#FIXME is this the number of classes? (check paper)\n",
    "\t])\n",
    "\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.01, momentum=0.9), \\\n",
    "              loss='categorical_crossentropy', \\\n",
    "              metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(5)])\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', \\\n",
    "                                            \t\tfactor=0.1, patience=1, \\\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tmin_lr=0.00001)\n",
    "model.fit(training_images, training_labels, batch_size=64, \\\n",
    "          validation_data=(valid_images, valid_labels), \\\n",
    "\t\t\t\t\tepochs=90, callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d43d1c-41ee-45f0-a341-3d2757eb5a12",
   "metadata": {},
   "source": [
    "## Evaluate the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c21960-4a3d-46cb-8dfd-d3b8a8314ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('test_images shape: {}'.format(test_images.shape))\n",
    "print('test_labels shape: {}'.format(test_labels.shape))\n",
    "\n",
    "results = model.evaluate(test_images,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b52e25-9d06-4e81-b6c7-d317e158b35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = (model.predict(test_images) > 0.5).astype(\"int32\")\n",
    "# print(\"Predictions (shape: {}):\\n{}\".format(predictions.shape, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a2dd7f-3232-4b86-84e0-4e4b7137660b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"test_classes: {}\".format(test_classes))\n",
    "# classification_report uses alphabetic ordering of the classes, so to match the encoded labels to the target_names, provide a sortest list of classes\n",
    "# https://stackoverflow.com/a/48495303\n",
    "sorted_test_classes = sorted(test_classes)\n",
    "print(classification_report(test_labels, predictions, target_names=sorted_test_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738305b2-92f1-41c1-a4f2-07171823ec10",
   "metadata": {},
   "source": [
    "# Save the model\n",
    "* use the current date/time so we can keep incrementation progress of the model as we re-run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e4681e-b9b8-419c-9cd5-bfd3b0a1763f",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "dt_string = now.strftime('%d-%m-%Y_%H:%M:%S')\n",
    "print(\"saving model as: 'ZFNet-{}.h5'.'\".format(dt_string))\n",
    "\n",
    "model.save('ZFNet-{}.h5'.format(dt_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006c0524-22ef-4ad4-8403-faec5dc9f5f4",
   "metadata": {},
   "source": [
    "## Free up the GPU's memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4c59ac-35fd-420c-ab71-2dc2c7c457ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda.select_device(0)\n",
    "cuda.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
